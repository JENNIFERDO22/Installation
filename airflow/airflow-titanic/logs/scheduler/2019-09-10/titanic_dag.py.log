[2019-09-10 10:17:18,093] {scheduler_job.py:146} INFO - Started process (PID=17838) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:17:18,095] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:17:18,095] {logging_mixin.py:95} INFO - [2019-09-10 10:17:18,095] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:17:18,490] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:17:18,491] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:17:18,590] {logging_mixin.py:95} INFO - [2019-09-10 10:17:18,589] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 13, in <module>
    from operations import *
ModuleNotFoundError: No module named 'operations'
[2019-09-10 10:17:18,590] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:17:18,616] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.523 seconds
[2019-09-10 10:18:00,136] {scheduler_job.py:146} INFO - Started process (PID=18021) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:00,138] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:18:00,138] {logging_mixin.py:95} INFO - [2019-09-10 10:18:00,138] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:00,531] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:18:00,531] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:18:00,614] {logging_mixin.py:95} INFO - [2019-09-10 10:18:00,614] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 13, in <module>
    from operations import *
ModuleNotFoundError: No module named 'operations'
[2019-09-10 10:18:00,614] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:00,646] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.509 seconds
[2019-09-10 10:18:42,193] {scheduler_job.py:146} INFO - Started process (PID=18139) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:42,197] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:18:42,197] {logging_mixin.py:95} INFO - [2019-09-10 10:18:42,197] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:42,482] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:18:42,483] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:18:42,553] {logging_mixin.py:95} INFO - [2019-09-10 10:18:42,553] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 13, in <module>
    from operations import *
ModuleNotFoundError: No module named 'operations'
[2019-09-10 10:18:42,553] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:18:42,576] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.383 seconds
[2019-09-10 10:19:24,222] {scheduler_job.py:146} INFO - Started process (PID=18299) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:19:24,224] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:19:24,224] {logging_mixin.py:95} INFO - [2019-09-10 10:19:24,224] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:19:24,538] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:19:24,538] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:19:24,610] {logging_mixin.py:95} INFO - [2019-09-10 10:19:24,609] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 13, in <module>
    from operations import *
ModuleNotFoundError: No module named 'operations'
[2019-09-10 10:19:24,610] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:19:24,636] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.414 seconds
[2019-09-10 10:20:06,263] {scheduler_job.py:146} INFO - Started process (PID=18363) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:06,265] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:20:06,265] {logging_mixin.py:95} INFO - [2019-09-10 10:20:06,265] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:06,626] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:20:06,626] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:20:06,757] {logging_mixin.py:95} INFO - [2019-09-10 10:20:06,757] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:20:13,385] {logging_mixin.py:95} INFO - [2019-09-10 10:20:13,376] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:20:13,386] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:13,430] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 7.167 seconds
[2019-09-10 10:20:48,307] {scheduler_job.py:146} INFO - Started process (PID=18491) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:48,309] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:20:48,309] {logging_mixin.py:95} INFO - [2019-09-10 10:20:48,309] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:48,665] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:20:48,665] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:20:48,797] {logging_mixin.py:95} INFO - [2019-09-10 10:20:48,796] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:20:53,226] {logging_mixin.py:95} INFO - [2019-09-10 10:20:53,224] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:20:53,227] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:20:53,254] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 4.947 seconds
[2019-09-10 10:21:30,361] {scheduler_job.py:146} INFO - Started process (PID=18656) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:21:30,366] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:21:30,367] {logging_mixin.py:95} INFO - [2019-09-10 10:21:30,367] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:21:30,662] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:21:30,662] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:21:30,740] {logging_mixin.py:95} INFO - [2019-09-10 10:21:30,739] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:21:35,423] {logging_mixin.py:95} INFO - [2019-09-10 10:21:35,418] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:21:35,424] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:21:35,459] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 5.098 seconds
[2019-09-10 10:26:38,204] {scheduler_job.py:146} INFO - Started process (PID=18979) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:26:38,207] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:26:38,208] {logging_mixin.py:95} INFO - [2019-09-10 10:26:38,208] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:26:38,520] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:26:38,521] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:26:38,615] {logging_mixin.py:95} INFO - [2019-09-10 10:26:38,615] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:26:44,111] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:26:44,114] {logging_mixin.py:95} INFO - [2019-09-10 10:26:44,114] {dag.py:1323} INFO - Creating ORM DAG for abbbbbbbbb_titanic_analysis
[2019-09-10 10:26:44,164] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 5.960 seconds
[2019-09-10 10:27:20,246] {scheduler_job.py:146} INFO - Started process (PID=19036) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:27:20,248] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:27:20,248] {logging_mixin.py:95} INFO - [2019-09-10 10:27:20,248] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:27:20,633] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:27:20,633] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:27:20,767] {logging_mixin.py:95} INFO - [2019-09-10 10:27:20,766] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:27:23,124] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:27:23,160] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.914 seconds
[2019-09-10 10:28:02,288] {scheduler_job.py:146} INFO - Started process (PID=19083) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:02,290] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:28:02,291] {logging_mixin.py:95} INFO - [2019-09-10 10:28:02,290] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:02,676] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:28:02,677] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:28:02,813] {logging_mixin.py:95} INFO - [2019-09-10 10:28:02,813] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:28:15,326] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:15,356] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 13.067 seconds
[2019-09-10 10:28:44,333] {scheduler_job.py:146} INFO - Started process (PID=19158) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:44,335] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:28:44,336] {logging_mixin.py:95} INFO - [2019-09-10 10:28:44,336] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:44,657] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:28:44,658] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:28:44,761] {logging_mixin.py:95} INFO - [2019-09-10 10:28:44,761] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:28:46,939] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:28:46,986] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.653 seconds
[2019-09-10 10:29:26,369] {scheduler_job.py:146} INFO - Started process (PID=19213) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:29:26,372] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:29:26,373] {logging_mixin.py:95} INFO - [2019-09-10 10:29:26,372] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:29:26,721] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:29:26,721] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:29:26,829] {logging_mixin.py:95} INFO - [2019-09-10 10:29:26,829] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:29:30,815] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:29:30,869] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 4.500 seconds
[2019-09-10 10:30:08,412] {scheduler_job.py:146} INFO - Started process (PID=19289) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:08,414] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:30:08,414] {logging_mixin.py:95} INFO - [2019-09-10 10:30:08,414] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:08,799] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:30:08,800] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:30:08,919] {logging_mixin.py:95} INFO - [2019-09-10 10:30:08,919] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:30:10,902] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:10,949] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.537 seconds
[2019-09-10 10:30:50,459] {scheduler_job.py:146} INFO - Started process (PID=19385) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:50,460] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:30:50,460] {logging_mixin.py:95} INFO - [2019-09-10 10:30:50,460] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:50,843] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:30:50,844] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:30:50,983] {logging_mixin.py:95} INFO - [2019-09-10 10:30:50,983] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:30:52,939] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:30:52,996] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.537 seconds
[2019-09-10 10:31:32,502] {scheduler_job.py:146} INFO - Started process (PID=19443) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:31:32,504] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:31:32,505] {logging_mixin.py:95} INFO - [2019-09-10 10:31:32,505] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:31:32,890] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:31:32,891] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:31:33,028] {logging_mixin.py:95} INFO - [2019-09-10 10:31:33,027] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:31:35,069] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:31:35,108] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.606 seconds
[2019-09-10 10:32:14,543] {scheduler_job.py:146} INFO - Started process (PID=19480) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:14,545] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:32:14,545] {logging_mixin.py:95} INFO - [2019-09-10 10:32:14,545] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:14,943] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:32:14,944] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:32:15,085] {logging_mixin.py:95} INFO - [2019-09-10 10:32:15,085] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:32:17,237] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:17,274] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.731 seconds
[2019-09-10 10:32:56,590] {scheduler_job.py:146} INFO - Started process (PID=19524) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:56,593] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:32:56,594] {logging_mixin.py:95} INFO - [2019-09-10 10:32:56,593] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:56,926] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:32:56,926] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:32:57,031] {logging_mixin.py:95} INFO - [2019-09-10 10:32:57,030] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:32:59,400] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:32:59,437] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.847 seconds
[2019-09-10 10:33:38,635] {scheduler_job.py:146} INFO - Started process (PID=19585) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:33:38,639] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:33:38,640] {logging_mixin.py:95} INFO - [2019-09-10 10:33:38,639] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:33:38,989] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:33:38,990] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:33:39,098] {logging_mixin.py:95} INFO - [2019-09-10 10:33:39,097] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:33:41,307] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:33:41,349] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.715 seconds
[2019-09-10 10:34:20,670] {scheduler_job.py:146} INFO - Started process (PID=19674) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:34:20,672] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:34:20,672] {logging_mixin.py:95} INFO - [2019-09-10 10:34:20,672] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:34:20,952] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:34:20,953] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:34:21,049] {logging_mixin.py:95} INFO - [2019-09-10 10:34:21,049] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:34:23,300] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:34:23,341] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:34:23,390] {scheduler_job.py:1265} INFO - Created <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01T00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:34:23,391] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:34:23,410] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:34:23,412] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:34:23,434] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.764 seconds
[2019-09-10 10:35:10,780] {scheduler_job.py:146} INFO - Started process (PID=19804) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:35:10,782] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:35:10,783] {logging_mixin.py:95} INFO - [2019-09-10 10:35:10,783] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:35:11,199] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:35:11,199] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:35:11,321] {logging_mixin.py:95} INFO - [2019-09-10 10:35:11,321] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:35:14,070] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:35:14,112] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:35:14,123] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:35:14,165] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:35:14,168] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:35:14,197] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.417 seconds
[2019-09-10 10:36:05,812] {scheduler_job.py:146} INFO - Started process (PID=19939) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:36:05,816] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:36:05,817] {logging_mixin.py:95} INFO - [2019-09-10 10:36:05,816] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:36:06,133] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:36:06,133] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:36:06,232] {logging_mixin.py:95} INFO - [2019-09-10 10:36:06,231] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:36:08,557] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:36:08,615] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:36:08,633] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:36:08,674] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:36:08,678] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:36:08,701] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.889 seconds
[2019-09-10 10:37:01,498] {scheduler_job.py:146} INFO - Started process (PID=20028) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:37:01,505] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:37:01,506] {logging_mixin.py:95} INFO - [2019-09-10 10:37:01,506] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:37:01,857] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:37:01,858] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:37:01,956] {logging_mixin.py:95} INFO - [2019-09-10 10:37:01,955] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:37:04,071] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:37:04,133] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:37:04,144] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:37:04,165] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:37:04,167] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:37:04,170] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:37:04,173] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:37:04,202] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.704 seconds
[2019-09-10 10:38:18,718] {scheduler_job.py:146} INFO - Started process (PID=20155) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:38:18,722] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:38:18,722] {logging_mixin.py:95} INFO - [2019-09-10 10:38:18,722] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:38:19,074] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:38:19,075] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:38:19,173] {logging_mixin.py:95} INFO - [2019-09-10 10:38:19,172] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:38:21,508] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:38:21,565] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:38:21,580] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:38:21,593] {logging_mixin.py:95} INFO - [2019-09-10 10:38:21,593] {dagrun.py:308} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 10:38:21,618] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:38:21,626] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.908 seconds
[2019-09-10 10:39:00,756] {scheduler_job.py:146} INFO - Started process (PID=20273) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:00,757] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:39:00,758] {logging_mixin.py:95} INFO - [2019-09-10 10:39:00,758] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:01,119] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:39:01,119] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:39:01,198] {logging_mixin.py:95} INFO - [2019-09-10 10:39:01,198] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:39:03,158] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:03,187] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:39:03,193] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:39:03,198] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.442 seconds
[2019-09-10 10:39:42,806] {scheduler_job.py:146} INFO - Started process (PID=20310) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:42,807] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:39:42,807] {logging_mixin.py:95} INFO - [2019-09-10 10:39:42,807] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:43,035] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:39:43,036] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:39:43,113] {logging_mixin.py:95} INFO - [2019-09-10 10:39:43,113] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:39:45,435] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:39:45,481] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:39:45,491] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:39:45,498] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.692 seconds
[2019-09-10 10:40:24,864] {scheduler_job.py:146} INFO - Started process (PID=20355) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:40:24,865] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:40:24,865] {logging_mixin.py:95} INFO - [2019-09-10 10:40:24,865] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:40:25,092] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:40:25,092] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:40:25,171] {logging_mixin.py:95} INFO - [2019-09-10 10:40:25,170] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:40:27,623] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:40:27,658] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:40:27,665] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:40:27,671] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.807 seconds
[2019-09-10 10:41:06,921] {scheduler_job.py:146} INFO - Started process (PID=20396) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:06,922] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:41:06,922] {logging_mixin.py:95} INFO - [2019-09-10 10:41:06,922] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:07,158] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:41:07,158] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:41:07,236] {logging_mixin.py:95} INFO - [2019-09-10 10:41:07,235] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:41:09,299] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:09,334] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:41:09,340] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:41:09,345] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.424 seconds
[2019-09-10 10:41:48,979] {scheduler_job.py:146} INFO - Started process (PID=20441) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:48,981] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:41:48,981] {logging_mixin.py:95} INFO - [2019-09-10 10:41:48,981] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:49,209] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:41:49,209] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:41:49,287] {logging_mixin.py:95} INFO - [2019-09-10 10:41:49,286] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:41:51,560] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:41:51,594] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:41:51,600] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:41:51,606] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.627 seconds
[2019-09-10 10:42:31,038] {scheduler_job.py:146} INFO - Started process (PID=20473) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:42:31,039] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:42:31,040] {logging_mixin.py:95} INFO - [2019-09-10 10:42:31,039] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:42:31,272] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:42:31,273] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:42:31,351] {logging_mixin.py:95} INFO - [2019-09-10 10:42:31,351] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:42:36,055] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:42:36,084] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:42:36,088] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:42:36,092] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 5.054 seconds
[2019-09-10 10:43:13,099] {scheduler_job.py:146} INFO - Started process (PID=20512) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:13,100] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:43:13,100] {logging_mixin.py:95} INFO - [2019-09-10 10:43:13,100] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:13,329] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:43:13,329] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:43:13,407] {logging_mixin.py:95} INFO - [2019-09-10 10:43:13,406] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:43:15,454] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:15,490] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:43:15,497] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:43:15,502] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.403 seconds
[2019-09-10 10:43:55,149] {scheduler_job.py:146} INFO - Started process (PID=20560) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:55,150] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:43:55,151] {logging_mixin.py:95} INFO - [2019-09-10 10:43:55,151] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:55,378] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:43:55,378] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:43:55,456] {logging_mixin.py:95} INFO - [2019-09-10 10:43:55,455] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:43:57,746] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:43:57,781] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:43:57,788] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:43:57,793] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.645 seconds
[2019-09-10 10:44:37,206] {scheduler_job.py:146} INFO - Started process (PID=20605) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:44:37,207] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:44:37,208] {logging_mixin.py:95} INFO - [2019-09-10 10:44:37,208] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:44:37,436] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:44:37,436] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:44:37,514] {logging_mixin.py:95} INFO - [2019-09-10 10:44:37,514] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:44:39,731] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:44:39,766] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:44:39,773] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:44:39,778] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.572 seconds
[2019-09-10 10:45:19,268] {scheduler_job.py:146} INFO - Started process (PID=20638) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:45:19,269] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:45:19,269] {logging_mixin.py:95} INFO - [2019-09-10 10:45:19,269] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:45:19,496] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:45:19,496] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:45:19,574] {logging_mixin.py:95} INFO - [2019-09-10 10:45:19,574] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:45:21,815] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:45:21,850] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:45:21,856] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:45:21,862] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.594 seconds
[2019-09-10 10:46:01,324] {scheduler_job.py:146} INFO - Started process (PID=20672) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:01,326] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:46:01,327] {logging_mixin.py:95} INFO - [2019-09-10 10:46:01,326] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:01,563] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:46:01,563] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:46:01,641] {logging_mixin.py:95} INFO - [2019-09-10 10:46:01,640] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:46:03,915] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:03,970] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:46:03,981] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:46:03,987] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.662 seconds
[2019-09-10 10:46:43,391] {scheduler_job.py:146} INFO - Started process (PID=20715) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:43,396] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:46:43,397] {logging_mixin.py:95} INFO - [2019-09-10 10:46:43,397] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:43,644] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:46:43,644] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:46:43,721] {logging_mixin.py:95} INFO - [2019-09-10 10:46:43,721] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:46:46,399] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:46:46,430] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:46:46,435] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:46:46,439] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.048 seconds
[2019-09-10 10:47:25,442] {scheduler_job.py:146} INFO - Started process (PID=20773) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:47:25,443] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:47:25,443] {logging_mixin.py:95} INFO - [2019-09-10 10:47:25,443] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:47:25,671] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:47:25,671] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:47:25,749] {logging_mixin.py:95} INFO - [2019-09-10 10:47:25,748] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:47:28,078] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:47:28,127] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:47:28,140] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:47:28,146] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.704 seconds
[2019-09-10 10:48:07,490] {scheduler_job.py:146} INFO - Started process (PID=20927) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:07,491] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:48:07,491] {logging_mixin.py:95} INFO - [2019-09-10 10:48:07,491] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:07,716] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:48:07,717] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:48:07,796] {logging_mixin.py:95} INFO - [2019-09-10 10:48:07,795] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:48:10,266] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:10,316] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:48:10,328] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:48:10,333] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.843 seconds
[2019-09-10 10:48:49,548] {scheduler_job.py:146} INFO - Started process (PID=20967) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:49,549] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:48:49,550] {logging_mixin.py:95} INFO - [2019-09-10 10:48:49,550] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:49,777] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:48:49,778] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:48:49,860] {logging_mixin.py:95} INFO - [2019-09-10 10:48:49,859] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:48:52,526] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:48:52,560] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:48:52,567] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:48:52,572] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.024 seconds
[2019-09-10 10:49:31,602] {scheduler_job.py:146} INFO - Started process (PID=21009) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:49:31,603] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:49:31,603] {logging_mixin.py:95} INFO - [2019-09-10 10:49:31,603] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:49:31,833] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:49:31,834] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:49:31,910] {logging_mixin.py:95} INFO - [2019-09-10 10:49:31,910] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:49:35,257] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:49:35,288] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:49:35,295] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:49:35,300] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.698 seconds
[2019-09-10 10:50:13,666] {scheduler_job.py:146} INFO - Started process (PID=21059) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:13,668] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:50:13,668] {logging_mixin.py:95} INFO - [2019-09-10 10:50:13,668] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:13,897] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:50:13,898] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:50:13,975] {logging_mixin.py:95} INFO - [2019-09-10 10:50:13,974] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:50:16,076] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:16,114] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:50:16,119] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:50:16,123] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.457 seconds
[2019-09-10 10:50:55,723] {scheduler_job.py:146} INFO - Started process (PID=21103) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:55,724] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:50:55,724] {logging_mixin.py:95} INFO - [2019-09-10 10:50:55,724] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:55,955] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:50:55,956] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:50:56,034] {logging_mixin.py:95} INFO - [2019-09-10 10:50:56,033] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:50:58,304] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:50:58,340] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:50:58,347] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:50:58,352] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.629 seconds
[2019-09-10 10:51:37,778] {scheduler_job.py:146} INFO - Started process (PID=21141) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:51:37,779] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:51:37,779] {logging_mixin.py:95} INFO - [2019-09-10 10:51:37,779] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:51:38,007] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:51:38,007] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:51:38,084] {logging_mixin.py:95} INFO - [2019-09-10 10:51:38,084] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:51:40,186] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:51:40,217] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:51:40,223] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:51:40,227] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.449 seconds
[2019-09-10 10:52:19,827] {scheduler_job.py:146} INFO - Started process (PID=21185) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:52:19,828] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:52:19,828] {logging_mixin.py:95} INFO - [2019-09-10 10:52:19,828] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:52:20,070] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:52:20,071] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:52:20,156] {logging_mixin.py:95} INFO - [2019-09-10 10:52:20,155] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:52:22,477] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:52:22,513] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:52:22,520] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:52:22,526] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.699 seconds
[2019-09-10 10:53:01,882] {scheduler_job.py:146} INFO - Started process (PID=21238) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:01,884] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:53:01,884] {logging_mixin.py:95} INFO - [2019-09-10 10:53:01,884] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:02,113] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:53:02,113] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:53:02,191] {logging_mixin.py:95} INFO - [2019-09-10 10:53:02,191] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:53:04,461] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:04,493] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:53:04,499] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:53:04,504] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.622 seconds
[2019-09-10 10:53:43,943] {scheduler_job.py:146} INFO - Started process (PID=21271) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:43,944] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:53:43,945] {logging_mixin.py:95} INFO - [2019-09-10 10:53:43,944] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:44,171] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:53:44,172] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:53:44,250] {logging_mixin.py:95} INFO - [2019-09-10 10:53:44,249] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:53:46,259] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:53:46,294] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:53:46,301] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:53:46,306] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.363 seconds
[2019-09-10 10:54:26,006] {scheduler_job.py:146} INFO - Started process (PID=21332) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:54:26,009] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:54:26,010] {logging_mixin.py:95} INFO - [2019-09-10 10:54:26,010] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:54:26,295] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:54:26,295] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:54:26,392] {logging_mixin.py:95} INFO - [2019-09-10 10:54:26,392] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:54:28,751] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:54:28,820] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:54:28,839] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:54:28,848] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.842 seconds
[2019-09-10 10:55:08,056] {scheduler_job.py:146} INFO - Started process (PID=21394) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:08,061] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:55:08,062] {logging_mixin.py:95} INFO - [2019-09-10 10:55:08,062] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:08,323] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:55:08,324] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:55:08,408] {logging_mixin.py:95} INFO - [2019-09-10 10:55:08,407] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:55:11,246] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:11,291] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:55:11,300] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:55:11,305] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.249 seconds
[2019-09-10 10:55:50,100] {scheduler_job.py:146} INFO - Started process (PID=21440) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:50,101] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:55:50,101] {logging_mixin.py:95} INFO - [2019-09-10 10:55:50,101] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:50,350] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:55:50,350] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:55:50,436] {logging_mixin.py:95} INFO - [2019-09-10 10:55:50,436] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:55:52,821] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:55:52,860] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:55:52,867] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:55:52,872] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.772 seconds
[2019-09-10 10:56:32,155] {scheduler_job.py:146} INFO - Started process (PID=21515) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:56:32,160] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:56:32,160] {logging_mixin.py:95} INFO - [2019-09-10 10:56:32,160] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:56:32,418] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:56:32,418] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:56:32,497] {logging_mixin.py:95} INFO - [2019-09-10 10:56:32,497] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:56:34,704] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:56:34,754] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:56:34,763] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:56:34,768] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.614 seconds
[2019-09-10 10:57:14,201] {scheduler_job.py:146} INFO - Started process (PID=21564) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:57:14,206] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:57:14,207] {logging_mixin.py:95} INFO - [2019-09-10 10:57:14,207] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:57:14,478] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:57:14,479] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:57:14,557] {logging_mixin.py:95} INFO - [2019-09-10 10:57:14,557] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:57:16,882] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:57:16,917] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:57:16,924] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:57:16,947] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:57:16,949] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:57:16,971] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.770 seconds
[2019-09-10 10:58:03,764] {scheduler_job.py:146} INFO - Started process (PID=21676) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:58:03,769] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:58:03,770] {logging_mixin.py:95} INFO - [2019-09-10 10:58:03,770] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:58:04,083] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:58:04,084] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:58:04,175] {logging_mixin.py:95} INFO - [2019-09-10 10:58:04,175] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:58:06,250] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:58:06,301] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:58:06,310] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:58:06,330] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:58:06,332] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:58:06,353] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.589 seconds
[2019-09-10 10:58:58,298] {scheduler_job.py:146} INFO - Started process (PID=21780) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:58:58,303] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:58:58,304] {logging_mixin.py:95} INFO - [2019-09-10 10:58:58,304] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:58:58,556] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:58:58,557] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:58:58,640] {logging_mixin.py:95} INFO - [2019-09-10 10:58:58,639] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:59:00,643] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:59:00,683] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:59:00,691] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:59:00,706] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:59:00,708] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:59:00,739] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.442 seconds
[2019-09-10 10:59:52,656] {scheduler_job.py:146} INFO - Started process (PID=21856) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:59:52,657] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 10:59:52,657] {logging_mixin.py:95} INFO - [2019-09-10 10:59:52,657] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:59:52,884] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:59:52,884] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:59:52,961] {logging_mixin.py:95} INFO - [2019-09-10 10:59:52,961] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:59:55,295] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 10:59:55,329] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 10:59:55,335] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:59:55,353] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:59:55,355] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:59:55,357] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:59:55,359] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:59:55,381] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.725 seconds
[2019-09-10 11:01:14,307] {scheduler_job.py:146} INFO - Started process (PID=22004) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:14,308] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 11:01:14,308] {logging_mixin.py:95} INFO - [2019-09-10 11:01:14,308] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:14,535] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 11:01:14,536] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 11:01:14,612] {logging_mixin.py:95} INFO - [2019-09-10 11:01:14,612] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 11:01:16,601] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:16,637] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 11:01:16,644] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 11:01:16,650] {logging_mixin.py:95} INFO - [2019-09-10 11:01:16,650] {dagrun.py:316} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> successful
[2019-09-10 11:01:16,669] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 11:01:16,674] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.367 seconds
[2019-09-10 11:01:56,363] {scheduler_job.py:146} INFO - Started process (PID=22045) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:56,368] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 11:01:56,369] {logging_mixin.py:95} INFO - [2019-09-10 11:01:56,369] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:56,638] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 11:01:56,639] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 11:01:56,721] {logging_mixin.py:95} INFO - [2019-09-10 11:01:56,721] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 11:01:59,013] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 11:01:59,044] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 11:01:59,055] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 11:01:59,062] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.698 seconds
[2019-09-10 16:58:40,991] {scheduler_job.py:146} INFO - Started process (PID=2976) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:58:40,993] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 16:58:40,993] {logging_mixin.py:95} INFO - [2019-09-10 16:58:40,993] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:58:41,226] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 16:58:41,227] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 16:58:41,306] {logging_mixin.py:95} INFO - [2019-09-10 16:58:41,306] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 16:58:50,771] {logging_mixin.py:95} INFO - [2019-09-10 16:58:50,761] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/home/jennie/anaconda3/lib/python3.7/socket.py", line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 262, in send
    chunked=self._chunked(request.headers),
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 641, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/retry.py", line 344, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 603, in urlopen
    chunked=chunked)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 344, in _make_request
    self._validate_conn(conn)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 843, in _validate_conn
    conn.connect()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 316, in connect
    conn = self._new_conn()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f85a666b9e8>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 648, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 667, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 102, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in _send_request
    success_response, exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 231, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 356, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 183, in __call__
    if self._checker(attempts, response, caught_exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 251, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 277, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 317, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 223, in __call__
    attempt_number, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 359, in _check_caught_exception
    raise caught_exception
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 200, in _do_get_response
    http_response = self._send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 244, in _send
    return self.http_session.send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 282, in send
    raise EndpointConnectionError(endpoint_url=request.url, error=e)
botocore.exceptions.EndpointConnectionError: Could not connect to the endpoint URL: "https://airflow-demo-09092019.s3.eu-west-1.amazonaws.com/?list-type=2&prefix=&delimiter=%2F&encoding-type=url"
[2019-09-10 16:58:50,771] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:58:50,804] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 9.812 seconds
[2019-09-10 16:59:23,046] {scheduler_job.py:146} INFO - Started process (PID=3019) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:59:23,052] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 16:59:23,053] {logging_mixin.py:95} INFO - [2019-09-10 16:59:23,053] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:59:23,320] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 16:59:23,320] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 16:59:23,403] {logging_mixin.py:95} INFO - [2019-09-10 16:59:23,402] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 16:59:29,169] {logging_mixin.py:95} INFO - [2019-09-10 16:59:29,156] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/home/jennie/anaconda3/lib/python3.7/socket.py", line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 262, in send
    chunked=self._chunked(request.headers),
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 641, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/retry.py", line 344, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 603, in urlopen
    chunked=chunked)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 344, in _make_request
    self._validate_conn(conn)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 843, in _validate_conn
    conn.connect()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 316, in connect
    conn = self._new_conn()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f85a666fe80>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 648, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 667, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 102, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in _send_request
    success_response, exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 231, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 356, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 183, in __call__
    if self._checker(attempts, response, caught_exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 251, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 277, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 317, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 223, in __call__
    attempt_number, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 359, in _check_caught_exception
    raise caught_exception
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 200, in _do_get_response
    http_response = self._send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 244, in _send
    return self.http_session.send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 282, in send
    raise EndpointConnectionError(endpoint_url=request.url, error=e)
botocore.exceptions.EndpointConnectionError: Could not connect to the endpoint URL: "https://airflow-demo-09092019.s3.eu-west-1.amazonaws.com/?list-type=2&prefix=&delimiter=%2F&encoding-type=url"
[2019-09-10 16:59:29,170] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 16:59:29,200] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 6.155 seconds
[2019-09-10 17:00:05,085] {scheduler_job.py:146} INFO - Started process (PID=3074) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:05,087] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:00:05,087] {logging_mixin.py:95} INFO - [2019-09-10 17:00:05,087] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:05,384] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:00:05,385] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:00:05,477] {logging_mixin.py:95} INFO - [2019-09-10 17:00:05,476] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:00:16,395] {logging_mixin.py:95} INFO - [2019-09-10 17:00:16,389] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/home/jennie/anaconda3/lib/python3.7/socket.py", line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 262, in send
    chunked=self._chunked(request.headers),
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 641, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/retry.py", line 344, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 603, in urlopen
    chunked=chunked)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 344, in _make_request
    self._validate_conn(conn)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 843, in _validate_conn
    conn.connect()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 316, in connect
    conn = self._new_conn()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f85a666fe48>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 648, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 667, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 102, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in _send_request
    success_response, exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 231, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 356, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 183, in __call__
    if self._checker(attempts, response, caught_exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 251, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 277, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 317, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 223, in __call__
    attempt_number, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 359, in _check_caught_exception
    raise caught_exception
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 200, in _do_get_response
    http_response = self._send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 244, in _send
    return self.http_session.send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 282, in send
    raise EndpointConnectionError(endpoint_url=request.url, error=e)
botocore.exceptions.EndpointConnectionError: Could not connect to the endpoint URL: "https://airflow-demo-09092019.s3.eu-west-1.amazonaws.com/?list-type=2&prefix=&delimiter=%2F&encoding-type=url"
[2019-09-10 17:00:16,395] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:16,421] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 11.336 seconds
[2019-09-10 17:00:47,141] {scheduler_job.py:146} INFO - Started process (PID=3130) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:47,143] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:00:47,143] {logging_mixin.py:95} INFO - [2019-09-10 17:00:47,143] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:47,370] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:00:47,370] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:00:47,371] {logging_mixin.py:95} INFO - [2019-09-10 17:00:47,371] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 10, in <module>
    from task4_pclass_most_survived import *
  File "/home/jennie/airflow/dags/task4_pclass_most_survived.py", line 5
    def most_survived_pclass(**context, titanic_df, s3, bucket_name):
                                                 ^
SyntaxError: invalid syntax
[2019-09-10 17:00:47,371] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:00:47,399] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.258 seconds
[2019-09-10 17:01:29,205] {scheduler_job.py:146} INFO - Started process (PID=3172) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:01:29,212] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:01:29,213] {logging_mixin.py:95} INFO - [2019-09-10 17:01:29,213] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:01:29,481] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:01:29,481] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:01:29,482] {logging_mixin.py:95} INFO - [2019-09-10 17:01:29,482] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 10, in <module>
    from task4_pclass_most_survived import *
  File "/home/jennie/airflow/dags/task4_pclass_most_survived.py", line 5
    def most_survived_pclass(**context, titanic_df, s3, bucket_name):
                                                 ^
SyntaxError: invalid syntax
[2019-09-10 17:01:29,482] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:01:29,509] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.304 seconds
[2019-09-10 17:02:11,250] {scheduler_job.py:146} INFO - Started process (PID=3232) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:11,252] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:02:11,252] {logging_mixin.py:95} INFO - [2019-09-10 17:02:11,252] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:11,477] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:02:11,478] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:02:11,479] {logging_mixin.py:95} INFO - [2019-09-10 17:02:11,478] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 10, in <module>
    from task4_pclass_most_survived import *
  File "/home/jennie/airflow/dags/task4_pclass_most_survived.py", line 5
    def most_survived_pclass(**context, s3, bucket_name):
                                         ^
SyntaxError: invalid syntax
[2019-09-10 17:02:11,479] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:11,502] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.251 seconds
[2019-09-10 17:02:53,297] {scheduler_job.py:146} INFO - Started process (PID=3298) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:53,299] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:02:53,299] {logging_mixin.py:95} INFO - [2019-09-10 17:02:53,299] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:53,534] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:02:53,534] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:02:53,535] {logging_mixin.py:95} INFO - [2019-09-10 17:02:53,535] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 10, in <module>
    from task4_pclass_most_survived import *
  File "/home/jennie/airflow/dags/task4_pclass_most_survived.py", line 5
    def most_survived_pclass(**context, s3, bucket_name):
                                         ^
SyntaxError: invalid syntax
[2019-09-10 17:02:53,535] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:02:53,558] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.260 seconds
[2019-09-10 17:03:35,357] {scheduler_job.py:146} INFO - Started process (PID=3387) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:03:35,362] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:03:35,363] {logging_mixin.py:95} INFO - [2019-09-10 17:03:35,362] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:03:35,627] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:03:35,628] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:03:35,629] {logging_mixin.py:95} INFO - [2019-09-10 17:03:35,628] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 10, in <module>
    from task4_pclass_most_survived import *
  File "/home/jennie/airflow/dags/task4_pclass_most_survived.py", line 5
    def most_survived_pclass(**context, s3, bucket_name):
                                         ^
SyntaxError: invalid syntax
[2019-09-10 17:03:35,629] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:03:35,655] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.299 seconds
[2019-09-10 17:04:17,406] {scheduler_job.py:146} INFO - Started process (PID=3440) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:17,407] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:04:17,407] {logging_mixin.py:95} INFO - [2019-09-10 17:04:17,407] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:17,635] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:04:17,636] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:04:17,696] {logging_mixin.py:95} INFO - [2019-09-10 17:04:17,695] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:04:17,696] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:17,722] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.316 seconds
[2019-09-10 17:04:59,462] {scheduler_job.py:146} INFO - Started process (PID=3482) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:59,463] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:04:59,463] {logging_mixin.py:95} INFO - [2019-09-10 17:04:59,463] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:59,691] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:04:59,691] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:04:59,750] {logging_mixin.py:95} INFO - [2019-09-10 17:04:59,750] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:04:59,750] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:04:59,777] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.315 seconds
[2019-09-10 17:05:41,521] {scheduler_job.py:146} INFO - Started process (PID=3547) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:05:41,522] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:05:41,522] {logging_mixin.py:95} INFO - [2019-09-10 17:05:41,522] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:05:41,753] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:05:41,753] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:05:41,813] {logging_mixin.py:95} INFO - [2019-09-10 17:05:41,812] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:05:41,813] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:05:41,837] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.316 seconds
[2019-09-10 17:06:23,572] {scheduler_job.py:146} INFO - Started process (PID=3590) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:06:23,574] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:06:23,574] {logging_mixin.py:95} INFO - [2019-09-10 17:06:23,574] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:06:23,820] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:06:23,820] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:06:23,883] {logging_mixin.py:95} INFO - [2019-09-10 17:06:23,883] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:06:23,883] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:06:23,907] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.335 seconds
[2019-09-10 17:07:05,632] {scheduler_job.py:146} INFO - Started process (PID=3642) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:05,634] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:07:05,634] {logging_mixin.py:95} INFO - [2019-09-10 17:07:05,634] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:05,861] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:07:05,861] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:07:05,920] {logging_mixin.py:95} INFO - [2019-09-10 17:07:05,920] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:07:05,920] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:05,948] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.315 seconds
[2019-09-10 17:07:47,691] {scheduler_job.py:146} INFO - Started process (PID=3693) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:47,696] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:07:47,697] {logging_mixin.py:95} INFO - [2019-09-10 17:07:47,697] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:47,945] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:07:47,945] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:07:48,012] {logging_mixin.py:95} INFO - [2019-09-10 17:07:48,012] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:07:48,013] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:07:48,035] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.343 seconds
[2019-09-10 17:08:29,743] {scheduler_job.py:146} INFO - Started process (PID=3757) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:08:29,749] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:08:29,750] {logging_mixin.py:95} INFO - [2019-09-10 17:08:29,750] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:08:30,124] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:08:30,124] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:08:30,184] {logging_mixin.py:95} INFO - [2019-09-10 17:08:30,183] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 11, in <module>
    from task5_avg_fare_by_pclass import *
  File "/home/jennie/airflow/dags/task5_avg_fare_by_pclass.py", line 1, in <module>
    from task4_pclass_most_survived import preprocessing, upload_result_to_s3, get_path
ImportError: cannot import name 'preprocessing' from 'task4_pclass_most_survived' (/home/jennie/airflow/dags/task4_pclass_most_survived.py)
[2019-09-10 17:08:30,184] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:08:30,209] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.466 seconds
[2019-09-10 17:09:11,786] {scheduler_job.py:146} INFO - Started process (PID=3825) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:09:11,791] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:09:11,792] {logging_mixin.py:95} INFO - [2019-09-10 17:09:11,792] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:09:12,044] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:09:12,045] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:09:12,129] {logging_mixin.py:95} INFO - [2019-09-10 17:09:12,129] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:09:19,168] {logging_mixin.py:95} INFO - [2019-09-10 17:09:19,158] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/home/jennie/anaconda3/lib/python3.7/socket.py", line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 262, in send
    chunked=self._chunked(request.headers),
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 641, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/retry.py", line 344, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 603, in urlopen
    chunked=chunked)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 344, in _make_request
    self._validate_conn(conn)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 843, in _validate_conn
    conn.connect()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 316, in connect
    conn = self._new_conn()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f85a6687278>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 648, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 667, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 102, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in _send_request
    success_response, exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 231, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 356, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 183, in __call__
    if self._checker(attempts, response, caught_exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 251, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 277, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 317, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 223, in __call__
    attempt_number, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 359, in _check_caught_exception
    raise caught_exception
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 200, in _do_get_response
    http_response = self._send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 244, in _send
    return self.http_session.send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 282, in send
    raise EndpointConnectionError(endpoint_url=request.url, error=e)
botocore.exceptions.EndpointConnectionError: Could not connect to the endpoint URL: "https://airflow-demo-09092019.s3.eu-west-1.amazonaws.com/?list-type=2&prefix=&delimiter=%2F&encoding-type=url"
[2019-09-10 17:09:19,168] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:09:19,205] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 7.419 seconds
[2019-09-10 17:09:53,835] {scheduler_job.py:146} INFO - Started process (PID=3880) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:09:53,840] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:09:53,840] {logging_mixin.py:95} INFO - [2019-09-10 17:09:53,840] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:09:54,090] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:09:54,090] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:09:54,176] {logging_mixin.py:95} INFO - [2019-09-10 17:09:54,176] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:10:05,834] {logging_mixin.py:95} INFO - [2019-09-10 17:10:05,824] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/titanic_dag.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/connection.py", line 57, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/home/jennie/anaconda3/lib/python3.7/socket.py", line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 262, in send
    chunked=self._chunked(request.headers),
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 641, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/util/retry.py", line 344, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/packages/six.py", line 686, in reraise
    raise value
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 603, in urlopen
    chunked=chunked)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 344, in _make_request
    self._validate_conn(conn)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connectionpool.py", line 843, in _validate_conn
    conn.connect()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 316, in connect
    conn = self._new_conn()
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/urllib3/connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f85a6687160>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/titanic_dag.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 648, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 667, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 102, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 137, in _send_request
    success_response, exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 231, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 356, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 183, in __call__
    if self._checker(attempts, response, caught_exception):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 251, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 277, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 317, in __call__
    caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 223, in __call__
    attempt_number, caught_exception)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/retryhandler.py", line 359, in _check_caught_exception
    raise caught_exception
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 200, in _do_get_response
    http_response = self._send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/endpoint.py", line 244, in _send
    return self.http_session.send(request)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/httpsession.py", line 282, in send
    raise EndpointConnectionError(endpoint_url=request.url, error=e)
botocore.exceptions.EndpointConnectionError: Could not connect to the endpoint URL: "https://airflow-demo-09092019.s3.eu-west-1.amazonaws.com/?list-type=2&prefix=&delimiter=%2F&encoding-type=url"
[2019-09-10 17:10:05,835] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:10:05,872] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 12.037 seconds
[2019-09-10 17:10:35,891] {scheduler_job.py:146} INFO - Started process (PID=4068) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:10:35,897] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:10:35,898] {logging_mixin.py:95} INFO - [2019-09-10 17:10:35,898] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:10:36,226] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:10:36,226] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:10:36,307] {logging_mixin.py:95} INFO - [2019-09-10 17:10:36,307] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:10:40,005] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:10:40,043] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:10:40,050] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:10:40,071] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 4.180 seconds
[2019-09-10 17:11:17,929] {scheduler_job.py:146} INFO - Started process (PID=4138) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:11:17,931] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:11:17,931] {logging_mixin.py:95} INFO - [2019-09-10 17:11:17,931] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:11:18,160] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:11:18,161] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:11:18,239] {logging_mixin.py:95} INFO - [2019-09-10 17:11:18,238] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:11:25,718] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:11:25,753] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:11:25,759] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:11:25,764] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 7.835 seconds
[2019-09-10 17:11:59,985] {scheduler_job.py:146} INFO - Started process (PID=4322) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:11:59,989] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:11:59,989] {logging_mixin.py:95} INFO - [2019-09-10 17:11:59,989] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:12:00,238] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:12:00,238] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:12:00,319] {logging_mixin.py:95} INFO - [2019-09-10 17:12:00,319] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:12:08,507] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:12:08,567] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:12:08,576] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:12:08,582] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 8.597 seconds
[2019-09-10 17:12:42,032] {scheduler_job.py:146} INFO - Started process (PID=4459) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:12:42,033] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:12:42,033] {logging_mixin.py:95} INFO - [2019-09-10 17:12:42,033] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:12:42,268] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:12:42,269] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:12:42,346] {logging_mixin.py:95} INFO - [2019-09-10 17:12:42,346] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:12:49,740] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:12:49,796] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:12:49,806] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:12:49,813] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 7.781 seconds
[2019-09-10 17:13:24,089] {scheduler_job.py:146} INFO - Started process (PID=4546) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:13:24,090] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:13:24,090] {logging_mixin.py:95} INFO - [2019-09-10 17:13:24,090] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:13:24,321] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:13:24,322] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:13:24,400] {logging_mixin.py:95} INFO - [2019-09-10 17:13:24,399] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:13:27,078] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:13:27,112] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:13:27,118] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:13:27,138] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:13:27,140] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:13:27,163] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.075 seconds
[2019-09-10 17:14:16,050] {scheduler_job.py:146} INFO - Started process (PID=4627) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:14:16,051] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:14:16,051] {logging_mixin.py:95} INFO - [2019-09-10 17:14:16,051] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:14:16,280] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:14:16,281] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:14:16,358] {logging_mixin.py:95} INFO - [2019-09-10 17:14:16,358] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:14:20,118] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:14:20,150] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:14:20,157] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:14:20,178] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:14:20,180] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:14:20,203] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 4.153 seconds
[2019-09-10 17:15:11,328] {scheduler_job.py:146} INFO - Started process (PID=4693) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:15:11,329] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:15:11,329] {logging_mixin.py:95} INFO - [2019-09-10 17:15:11,329] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:15:11,560] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:15:11,561] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:15:11,638] {logging_mixin.py:95} INFO - [2019-09-10 17:15:11,637] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:15:14,283] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:15:14,334] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:15:14,347] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:15:14,368] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:15:14,369] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:15:14,392] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.064 seconds
[2019-09-10 17:16:05,923] {scheduler_job.py:146} INFO - Started process (PID=4770) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:16:05,925] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:16:05,925] {logging_mixin.py:95} INFO - [2019-09-10 17:16:05,925] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:16:06,151] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:16:06,152] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:16:06,233] {logging_mixin.py:95} INFO - [2019-09-10 17:16:06,233] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:16:08,390] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:16:08,425] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:16:08,431] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:16:08,448] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:16:08,450] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:16:08,452] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:16:08,454] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:16:08,477] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.554 seconds
[2019-09-10 17:17:28,964] {scheduler_job.py:146} INFO - Started process (PID=4936) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:17:28,970] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:17:28,971] {logging_mixin.py:95} INFO - [2019-09-10 17:17:28,971] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:17:29,215] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:17:29,215] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:17:29,293] {logging_mixin.py:95} INFO - [2019-09-10 17:17:29,292] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:17:31,258] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:17:31,284] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:17:31,289] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:17:31,294] {logging_mixin.py:95} INFO - [2019-09-10 17:17:31,294] {dagrun.py:316} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> successful
[2019-09-10 17:17:31,312] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:17:31,315] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.351 seconds
[2019-09-10 17:18:11,010] {scheduler_job.py:146} INFO - Started process (PID=5078) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:11,011] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:18:11,011] {logging_mixin.py:95} INFO - [2019-09-10 17:18:11,011] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:11,237] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:18:11,238] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:18:11,315] {logging_mixin.py:95} INFO - [2019-09-10 17:18:11,315] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:18:14,026] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:14,056] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:18:14,063] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:18:14,068] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 3.058 seconds
[2019-09-10 17:18:53,055] {scheduler_job.py:146} INFO - Started process (PID=5141) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:53,056] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:18:53,057] {logging_mixin.py:95} INFO - [2019-09-10 17:18:53,056] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:53,287] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:18:53,288] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:18:53,366] {logging_mixin.py:95} INFO - [2019-09-10 17:18:53,365] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:18:55,711] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:18:55,762] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:18:55,771] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:18:55,777] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.722 seconds
[2019-09-10 17:19:35,109] {scheduler_job.py:146} INFO - Started process (PID=5185) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:19:35,110] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:19:35,110] {logging_mixin.py:95} INFO - [2019-09-10 17:19:35,110] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:19:35,352] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:19:35,353] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:19:35,460] {logging_mixin.py:95} INFO - [2019-09-10 17:19:35,460] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:19:37,686] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:19:37,726] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:19:37,732] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:19:37,737] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.628 seconds
[2019-09-10 17:20:17,166] {scheduler_job.py:146} INFO - Started process (PID=5240) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:17,171] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:20:17,172] {logging_mixin.py:95} INFO - [2019-09-10 17:20:17,172] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:17,447] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:20:17,447] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:20:17,526] {logging_mixin.py:95} INFO - [2019-09-10 17:20:17,526] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:20:19,759] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:19,786] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:20:19,791] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:20:19,795] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 2.629 seconds
[2019-09-10 17:20:59,225] {scheduler_job.py:146} INFO - Started process (PID=5308) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:59,231] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:20:59,232] {logging_mixin.py:95} INFO - [2019-09-10 17:20:59,231] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:59,572] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:20:59,573] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:20:59,674] {logging_mixin.py:95} INFO - [2019-09-10 17:20:59,673] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:20:59,746] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:20:59,782] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:20:59,786] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:20:59,803] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:20:59,805] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:20:59,828] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.603 seconds
[2019-09-10 17:21:47,050] {scheduler_job.py:146} INFO - Started process (PID=5377) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:21:47,052] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:21:47,052] {logging_mixin.py:95} INFO - [2019-09-10 17:21:47,052] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:21:47,279] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:21:47,279] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:21:47,357] {logging_mixin.py:95} INFO - [2019-09-10 17:21:47,356] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:21:47,417] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:21:47,451] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:21:47,455] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:21:47,475] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:21:47,477] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:21:47,501] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.451 seconds
[2019-09-10 17:22:34,413] {scheduler_job.py:146} INFO - Started process (PID=5447) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:22:34,414] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:22:34,414] {logging_mixin.py:95} INFO - [2019-09-10 17:22:34,414] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:22:34,646] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:22:34,647] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:22:34,724] {logging_mixin.py:95} INFO - [2019-09-10 17:22:34,724] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:22:34,786] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:22:34,823] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:22:34,827] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:22:34,842] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:22:34,844] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:22:34,871] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.458 seconds
[2019-09-10 17:23:51,982] {scheduler_job.py:146} INFO - Started process (PID=5542) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:23:51,983] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:23:51,983] {logging_mixin.py:95} INFO - [2019-09-10 17:23:51,983] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:23:52,290] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:23:52,290] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:23:52,400] {logging_mixin.py:95} INFO - [2019-09-10 17:23:52,399] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:23:52,468] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:23:52,499] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:23:52,504] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:23:52,521] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:23:52,523] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:23:52,526] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:23:52,528] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:23:52,553] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.571 seconds
[2019-09-10 17:26:47,889] {scheduler_job.py:146} INFO - Started process (PID=5791) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:26:47,890] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:26:47,890] {logging_mixin.py:95} INFO - [2019-09-10 17:26:47,890] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:26:48,135] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:26:48,135] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:26:48,218] {logging_mixin.py:95} INFO - [2019-09-10 17:26:48,217] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:26:48,280] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:26:48,313] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:26:48,317] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:26:48,393] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:26:48,400] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.511 seconds
[2019-09-10 17:27:29,939] {scheduler_job.py:146} INFO - Started process (PID=5875) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:27:29,944] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:27:29,945] {logging_mixin.py:95} INFO - [2019-09-10 17:27:29,944] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:27:30,240] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:27:30,240] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:27:30,318] {logging_mixin.py:95} INFO - [2019-09-10 17:27:30,317] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:27:30,377] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:27:30,418] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:27:30,426] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:27:30,433] {logging_mixin.py:95} INFO - [2019-09-10 17:27:30,433] {dagrun.py:308} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 17:27:30,451] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:27:30,454] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.515 seconds
[2019-09-10 17:28:11,989] {scheduler_job.py:146} INFO - Started process (PID=5913) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:11,990] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:28:11,990] {logging_mixin.py:95} INFO - [2019-09-10 17:28:11,990] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:12,217] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:28:12,217] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:28:12,295] {logging_mixin.py:95} INFO - [2019-09-10 17:28:12,295] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:28:12,354] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:12,393] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:28:12,397] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:28:12,417] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:28:12,419] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:28:12,444] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.455 seconds
[2019-09-10 17:28:59,371] {scheduler_job.py:146} INFO - Started process (PID=5991) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:59,372] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:28:59,373] {logging_mixin.py:95} INFO - [2019-09-10 17:28:59,373] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:59,603] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:28:59,603] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:28:59,684] {logging_mixin.py:95} INFO - [2019-09-10 17:28:59,684] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:28:59,746] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:28:59,779] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:28:59,783] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:28:59,801] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:28:59,803] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:28:59,835] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.464 seconds
[2019-09-10 17:29:46,777] {scheduler_job.py:146} INFO - Started process (PID=6052) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:29:46,778] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:29:46,779] {logging_mixin.py:95} INFO - [2019-09-10 17:29:46,779] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:29:47,005] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:29:47,006] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:29:47,083] {logging_mixin.py:95} INFO - [2019-09-10 17:29:47,083] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:29:47,144] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:29:47,178] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:29:47,182] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:29:47,199] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:29:47,201] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:29:47,224] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.447 seconds
[2019-09-10 17:30:34,182] {scheduler_job.py:146} INFO - Started process (PID=6134) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:30:34,183] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:30:34,184] {logging_mixin.py:95} INFO - [2019-09-10 17:30:34,184] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:30:34,413] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:30:34,414] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:30:34,494] {logging_mixin.py:95} INFO - [2019-09-10 17:30:34,493] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:30:34,556] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:30:34,589] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:30:34,593] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:30:34,609] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:30:34,610] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:30:34,612] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:30:34,614] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:30:34,637] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.455 seconds
[2019-09-10 17:31:34,022] {scheduler_job.py:146} INFO - Started process (PID=6255) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:31:34,024] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:31:34,024] {logging_mixin.py:95} INFO - [2019-09-10 17:31:34,024] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:31:34,251] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:31:34,251] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:31:34,328] {logging_mixin.py:95} INFO - [2019-09-10 17:31:34,328] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:31:34,387] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:31:34,422] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:31:34,426] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:31:34,441] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:31:34,444] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.end 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:31:34,468] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.445 seconds
[2019-09-10 17:32:21,479] {scheduler_job.py:146} INFO - Started process (PID=6319) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:32:21,480] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:32:21,480] {logging_mixin.py:95} INFO - [2019-09-10 17:32:21,480] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:32:21,712] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:32:21,713] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:32:21,790] {logging_mixin.py:95} INFO - [2019-09-10 17:32:21,790] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:32:21,849] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:32:21,883] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:32:21,887] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:32:21,892] {logging_mixin.py:95} INFO - [2019-09-10 17:32:21,892] {dagrun.py:316} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> successful
[2019-09-10 17:32:21,910] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:32:21,913] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.434 seconds
[2019-09-10 17:33:03,533] {scheduler_job.py:146} INFO - Started process (PID=6367) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:03,535] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:33:03,535] {logging_mixin.py:95} INFO - [2019-09-10 17:33:03,535] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:03,762] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:33:03,762] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:33:03,839] {logging_mixin.py:95} INFO - [2019-09-10 17:33:03,839] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:33:03,901] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:03,934] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:33:03,938] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:33:03,955] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:33:03,957] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:33:03,979] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.446 seconds
[2019-09-10 17:33:50,916] {scheduler_job.py:146} INFO - Started process (PID=6429) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:50,918] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:33:50,918] {logging_mixin.py:95} INFO - [2019-09-10 17:33:50,918] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:51,149] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:33:51,150] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:33:51,228] {logging_mixin.py:95} INFO - [2019-09-10 17:33:51,228] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:33:51,290] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:33:51,319] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:33:51,323] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:33:51,342] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:33:51,343] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:33:51,366] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.449 seconds
[2019-09-10 17:34:53,287] {scheduler_job.py:146} INFO - Started process (PID=6509) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:34:53,288] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:34:53,288] {logging_mixin.py:95} INFO - [2019-09-10 17:34:53,288] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:34:53,514] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:34:53,515] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:34:53,597] {logging_mixin.py:95} INFO - [2019-09-10 17:34:53,596] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:34:53,658] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:34:53,690] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:34:53,694] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:34:53,714] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:34:53,715] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:34:53,748] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.461 seconds
[2019-09-10 17:35:40,646] {scheduler_job.py:146} INFO - Started process (PID=6575) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:35:40,648] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:35:40,648] {logging_mixin.py:95} INFO - [2019-09-10 17:35:40,648] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:35:40,880] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:35:40,880] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:35:40,958] {logging_mixin.py:95} INFO - [2019-09-10 17:35:40,958] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:35:41,020] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:35:41,053] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:35:41,058] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:35:41,073] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:35:41,075] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:35:41,077] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:35:41,078] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:35:41,101] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.454 seconds
[2019-09-10 17:36:40,567] {scheduler_job.py:146} INFO - Started process (PID=6702) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:36:40,568] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:36:40,568] {logging_mixin.py:95} INFO - [2019-09-10 17:36:40,568] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:36:40,801] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:36:40,802] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:36:40,880] {logging_mixin.py:95} INFO - [2019-09-10 17:36:40,880] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:36:40,943] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:36:40,976] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:36:40,980] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:36:40,991] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:36:40,992] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: abbbbbbbbb_titanic_analysis.end 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 17:36:41,011] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.445 seconds
[2019-09-10 17:37:28,613] {scheduler_job.py:146} INFO - Started process (PID=6770) to work on /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:37:28,618] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/titanic_dag.py for tasks to queue
[2019-09-10 17:37:28,619] {logging_mixin.py:95} INFO - [2019-09-10 17:37:28,619] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:37:28,893] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:37:28,894] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 17:37:28,982] {logging_mixin.py:95} INFO - [2019-09-10 17:37:28,981] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 17:37:29,048] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['abbbbbbbbb_titanic_analysis']) retrieved from /home/jennie/airflow/dags/titanic_dag.py
[2019-09-10 17:37:29,081] {scheduler_job.py:1255} INFO - Processing abbbbbbbbb_titanic_analysis
[2019-09-10 17:37:29,088] {scheduler_job.py:729} INFO - Examining DAG run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 17:37:29,093] {logging_mixin.py:95} INFO - [2019-09-10 17:37:29,093] {dagrun.py:316} INFO - Marking run <DagRun abbbbbbbbb_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> successful
[2019-09-10 17:37:29,111] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: abbbbbbbbb_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 17:37:29,114] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/titanic_dag.py took 0.501 seconds
