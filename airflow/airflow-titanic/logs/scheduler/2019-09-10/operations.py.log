[2019-09-10 08:52:55,959] {scheduler_job.py:146} INFO - Started process (PID=10197) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:52:55,964] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:52:55,965] {logging_mixin.py:95} INFO - [2019-09-10 08:52:55,965] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:52:55,975] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:52:55,977] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:52:55,978] {logging_mixin.py:95} INFO - [2019-09-10 08:52:55,977] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 9, in <module>
    'start_date': datetime(2019, 1, 1),
NameError: name 'datetime' is not defined
[2019-09-10 08:52:55,978] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:52:56,010] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.051 seconds
[2019-09-10 08:53:37,995] {scheduler_job.py:146} INFO - Started process (PID=10265) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:53:37,996] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:53:37,997] {logging_mixin.py:95} INFO - [2019-09-10 08:53:37,997] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:53:38,001] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:53:38,002] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:53:38,004] {logging_mixin.py:95} INFO - [2019-09-10 08:53:38,003] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 26, in <module>
    python_callable= upload_file_to_s3,
NameError: name 'upload_file_to_s3' is not defined
[2019-09-10 08:53:38,004] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:53:38,033] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.039 seconds
[2019-09-10 08:54:20,060] {scheduler_job.py:146} INFO - Started process (PID=10361) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:54:20,063] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:54:20,064] {logging_mixin.py:95} INFO - [2019-09-10 08:54:20,064] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:54:20,070] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:54:20,071] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:54:20,072] {logging_mixin.py:95} INFO - [2019-09-10 08:54:20,072] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 26, in <module>
    python_callable= upload_file_to_s3,
NameError: name 'upload_file_to_s3' is not defined
[2019-09-10 08:54:20,073] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:54:20,100] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.041 seconds
[2019-09-10 08:55:02,096] {scheduler_job.py:146} INFO - Started process (PID=10393) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:02,097] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:55:02,097] {logging_mixin.py:95} INFO - [2019-09-10 08:55:02,097] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:02,100] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:55:02,101] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:55:02,101] {logging_mixin.py:95} INFO - [2019-09-10 08:55:02,101] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 26, in <module>
    python_callable= upload_file_to_s3,
NameError: name 'upload_file_to_s3' is not defined
[2019-09-10 08:55:02,102] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:02,128] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.033 seconds
[2019-09-10 08:55:44,152] {scheduler_job.py:146} INFO - Started process (PID=10456) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:44,157] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:55:44,158] {logging_mixin.py:95} INFO - [2019-09-10 08:55:44,157] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:44,169] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:55:44,171] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:55:44,174] {logging_mixin.py:95} INFO - [2019-09-10 08:55:44,173] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 28, in <module>
    'filename': local_filename,
NameError: name 'local_filename' is not defined
[2019-09-10 08:55:44,175] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:55:44,207] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.055 seconds
[2019-09-10 08:56:26,199] {scheduler_job.py:146} INFO - Started process (PID=10501) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:56:26,204] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:56:26,204] {logging_mixin.py:95} INFO - [2019-09-10 08:56:26,204] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:56:26,212] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:56:26,213] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:56:26,214] {logging_mixin.py:95} INFO - [2019-09-10 08:56:26,214] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 28, in <module>
    'filename': local_filename,
NameError: name 'local_filename' is not defined
[2019-09-10 08:56:26,215] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:56:26,235] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.036 seconds
[2019-09-10 08:57:08,236] {scheduler_job.py:146} INFO - Started process (PID=10557) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:08,239] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:57:08,239] {logging_mixin.py:95} INFO - [2019-09-10 08:57:08,239] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:08,285] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:57:08,285] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:57:08,304] {logging_mixin.py:95} INFO - [2019-09-10 08:57:08,304] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 08:57:08,330] {logging_mixin.py:95} INFO - [2019-09-10 08:57:08,329] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 08:57:08,330] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:08,352] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.116 seconds
[2019-09-10 08:57:50,296] {scheduler_job.py:146} INFO - Started process (PID=10601) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:50,301] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:57:50,302] {logging_mixin.py:95} INFO - [2019-09-10 08:57:50,302] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:50,356] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:57:50,356] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:57:50,375] {logging_mixin.py:95} INFO - [2019-09-10 08:57:50,375] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 08:57:50,398] {logging_mixin.py:95} INFO - [2019-09-10 08:57:50,398] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 08:57:50,399] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:57:50,428] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.132 seconds
[2019-09-10 08:58:32,347] {scheduler_job.py:146} INFO - Started process (PID=10634) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:58:32,348] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:58:32,349] {logging_mixin.py:95} INFO - [2019-09-10 08:58:32,349] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:58:32,386] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:58:32,387] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:58:32,405] {logging_mixin.py:95} INFO - [2019-09-10 08:58:32,405] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 08:58:32,429] {logging_mixin.py:95} INFO - [2019-09-10 08:58:32,428] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 08:58:32,429] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:58:32,457] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.110 seconds
[2019-09-10 08:59:14,415] {scheduler_job.py:146} INFO - Started process (PID=10668) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:14,421] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:59:14,422] {logging_mixin.py:95} INFO - [2019-09-10 08:59:14,422] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:14,484] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:59:14,484] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:59:14,504] {logging_mixin.py:95} INFO - [2019-09-10 08:59:14,504] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 08:59:14,528] {logging_mixin.py:95} INFO - [2019-09-10 08:59:14,527] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 08:59:14,528] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:14,556] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.141 seconds
[2019-09-10 08:59:56,469] {scheduler_job.py:146} INFO - Started process (PID=10717) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:56,470] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 08:59:56,471] {logging_mixin.py:95} INFO - [2019-09-10 08:59:56,470] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:56,510] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:59:56,511] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 08:59:56,529] {logging_mixin.py:95} INFO - [2019-09-10 08:59:56,529] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 08:59:56,553] {logging_mixin.py:95} INFO - [2019-09-10 08:59:56,552] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 08:59:56,553] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 08:59:56,580] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.111 seconds
[2019-09-10 09:00:38,525] {scheduler_job.py:146} INFO - Started process (PID=10755) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:00:38,530] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:00:38,531] {logging_mixin.py:95} INFO - [2019-09-10 09:00:38,531] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:00:38,583] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:00:38,583] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:00:38,604] {logging_mixin.py:95} INFO - [2019-09-10 09:00:38,604] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:00:38,629] {logging_mixin.py:95} INFO - [2019-09-10 09:00:38,629] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:00:38,629] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:00:38,654] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.129 seconds
[2019-09-10 09:01:20,561] {scheduler_job.py:146} INFO - Started process (PID=10801) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:01:20,563] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:01:20,563] {logging_mixin.py:95} INFO - [2019-09-10 09:01:20,563] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:01:20,608] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:01:20,608] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:01:20,627] {logging_mixin.py:95} INFO - [2019-09-10 09:01:20,627] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:01:20,653] {logging_mixin.py:95} INFO - [2019-09-10 09:01:20,652] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:01:20,653] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:01:20,680] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.119 seconds
[2019-09-10 09:02:02,627] {scheduler_job.py:146} INFO - Started process (PID=10841) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:02,632] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:02:02,633] {logging_mixin.py:95} INFO - [2019-09-10 09:02:02,633] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:02,704] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:02:02,704] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:02:02,725] {logging_mixin.py:95} INFO - [2019-09-10 09:02:02,725] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:02:02,753] {logging_mixin.py:95} INFO - [2019-09-10 09:02:02,753] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:02:02,753] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:02,781] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.154 seconds
[2019-09-10 09:02:44,681] {scheduler_job.py:146} INFO - Started process (PID=10887) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:44,684] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:02:44,685] {logging_mixin.py:95} INFO - [2019-09-10 09:02:44,685] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:44,749] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:02:44,750] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:02:44,768] {logging_mixin.py:95} INFO - [2019-09-10 09:02:44,768] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:02:44,793] {logging_mixin.py:95} INFO - [2019-09-10 09:02:44,792] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:02:44,793] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:02:44,825] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.145 seconds
[2019-09-10 09:03:26,731] {scheduler_job.py:146} INFO - Started process (PID=10928) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:03:26,732] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:03:26,732] {logging_mixin.py:95} INFO - [2019-09-10 09:03:26,732] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:03:26,774] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:03:26,774] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:03:26,793] {logging_mixin.py:95} INFO - [2019-09-10 09:03:26,792] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:03:26,818] {logging_mixin.py:95} INFO - [2019-09-10 09:03:26,818] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:03:26,819] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:03:26,847] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.116 seconds
[2019-09-10 09:04:08,784] {scheduler_job.py:146} INFO - Started process (PID=10974) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:08,785] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:04:08,785] {logging_mixin.py:95} INFO - [2019-09-10 09:04:08,785] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:08,828] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:04:08,828] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:04:08,846] {logging_mixin.py:95} INFO - [2019-09-10 09:04:08,846] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:04:08,870] {logging_mixin.py:95} INFO - [2019-09-10 09:04:08,870] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:04:08,870] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:08,897] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.114 seconds
[2019-09-10 09:04:50,832] {scheduler_job.py:146} INFO - Started process (PID=11006) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:50,834] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:04:50,834] {logging_mixin.py:95} INFO - [2019-09-10 09:04:50,834] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:50,891] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:04:50,891] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:04:50,909] {logging_mixin.py:95} INFO - [2019-09-10 09:04:50,909] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:04:50,933] {logging_mixin.py:95} INFO - [2019-09-10 09:04:50,932] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 60, in <module>
    'titanic_df': titanic_df
NameError: name 'titanic_df' is not defined
[2019-09-10 09:04:50,933] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:04:50,960] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.129 seconds
[2019-09-10 09:05:32,895] {scheduler_job.py:146} INFO - Started process (PID=11048) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:05:32,900] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:05:32,901] {logging_mixin.py:95} INFO - [2019-09-10 09:05:32,901] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:05:32,964] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:05:32,964] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:05:32,984] {logging_mixin.py:95} INFO - [2019-09-10 09:05:32,984] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:05:33,009] {logging_mixin.py:95} INFO - [2019-09-10 09:05:33,008] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 57, in <module>
    train_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 5, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
NameError: name 'pd' is not defined
[2019-09-10 09:05:33,009] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:05:33,034] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.139 seconds
[2019-09-10 09:06:14,946] {scheduler_job.py:146} INFO - Started process (PID=11107) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:14,951] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:06:14,952] {logging_mixin.py:95} INFO - [2019-09-10 09:06:14,952] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:15,034] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:06:15,035] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:06:15,061] {logging_mixin.py:95} INFO - [2019-09-10 09:06:15,061] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:06:15,088] {logging_mixin.py:95} INFO - [2019-09-10 09:06:15,087] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 11, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 57, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 5, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
NameError: name 'pd' is not defined
[2019-09-10 09:06:15,088] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:15,113] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.167 seconds
[2019-09-10 09:06:56,980] {scheduler_job.py:146} INFO - Started process (PID=11159) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:56,981] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:06:56,982] {logging_mixin.py:95} INFO - [2019-09-10 09:06:56,982] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:57,220] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:06:57,221] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:06:57,246] {logging_mixin.py:95} INFO - [2019-09-10 09:06:57,245] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:06:57,280] {logging_mixin.py:95} INFO - [2019-09-10 09:06:57,279] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 56, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 5, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
NameError: name 'pd' is not defined
[2019-09-10 09:06:57,280] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:06:57,317] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.337 seconds
[2019-09-10 09:07:39,035] {scheduler_job.py:146} INFO - Started process (PID=11205) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:07:39,040] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:07:39,041] {logging_mixin.py:95} INFO - [2019-09-10 09:07:39,041] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:07:39,294] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:07:39,294] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:07:39,314] {logging_mixin.py:95} INFO - [2019-09-10 09:07:39,313] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:07:43,324] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:07:43,339] {logging_mixin.py:95} INFO - [2019-09-10 09:07:43,339] {dag.py:1323} INFO - Creating ORM DAG for ahhaha_titanic_analysis
[2019-09-10 09:07:43,386] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.351 seconds
[2019-09-10 09:08:21,082] {scheduler_job.py:146} INFO - Started process (PID=11246) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:08:21,083] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:08:21,083] {logging_mixin.py:95} INFO - [2019-09-10 09:08:21,083] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:08:21,325] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:08:21,325] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:08:21,343] {logging_mixin.py:95} INFO - [2019-09-10 09:08:21,343] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:08:25,492] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:08:25,524] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.443 seconds
[2019-09-10 09:09:03,137] {scheduler_job.py:146} INFO - Started process (PID=11282) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:03,138] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:09:03,138] {logging_mixin.py:95} INFO - [2019-09-10 09:09:03,138] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:03,373] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:09:03,374] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:09:03,392] {logging_mixin.py:95} INFO - [2019-09-10 09:09:03,392] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:09:10,242] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:10,277] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 7.140 seconds
[2019-09-10 09:09:45,195] {scheduler_job.py:146} INFO - Started process (PID=11317) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:45,200] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:09:45,201] {logging_mixin.py:95} INFO - [2019-09-10 09:09:45,201] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:45,459] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:09:45,460] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:09:45,479] {logging_mixin.py:95} INFO - [2019-09-10 09:09:45,478] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:09:50,751] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:09:50,800] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.605 seconds
[2019-09-10 09:10:27,249] {scheduler_job.py:146} INFO - Started process (PID=11366) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:10:27,254] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:10:27,254] {logging_mixin.py:95} INFO - [2019-09-10 09:10:27,254] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:10:27,519] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:10:27,520] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:10:27,538] {logging_mixin.py:95} INFO - [2019-09-10 09:10:27,538] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:10:31,523] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:10:31,573] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:10:31,641] {scheduler_job.py:1265} INFO - Created <DagRun ahhaha_titanic_analysis @ 2019-01-01T00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:10:31,647] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:10:31,670] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:10:31,673] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:10:31,693] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.445 seconds
[2019-09-10 09:11:25,935] {scheduler_job.py:146} INFO - Started process (PID=11436) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:11:25,936] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:11:25,936] {logging_mixin.py:95} INFO - [2019-09-10 09:11:25,936] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:11:26,184] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:11:26,184] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:11:26,203] {logging_mixin.py:95} INFO - [2019-09-10 09:11:26,203] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:11:32,803] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:11:32,838] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:11:32,845] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:11:32,864] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:11:32,866] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:11:32,889] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.954 seconds
[2019-09-10 09:12:25,910] {scheduler_job.py:146} INFO - Started process (PID=11499) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:12:25,911] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:12:25,911] {logging_mixin.py:95} INFO - [2019-09-10 09:12:25,911] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:12:26,138] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:12:26,138] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:12:26,157] {logging_mixin.py:95} INFO - [2019-09-10 09:12:26,156] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:12:30,064] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:12:30,122] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:12:30,132] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:12:30,184] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:12:30,188] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.278 seconds
[2019-09-10 09:13:07,965] {scheduler_job.py:146} INFO - Started process (PID=11533) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:07,966] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:13:07,966] {logging_mixin.py:95} INFO - [2019-09-10 09:13:07,966] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:08,195] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:13:08,195] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:13:08,214] {logging_mixin.py:95} INFO - [2019-09-10 09:13:08,213] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:13:12,358] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:12,393] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:13:12,399] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:13:12,405] {logging_mixin.py:95} INFO - [2019-09-10 09:13:12,405] {dagrun.py:308} INFO - Marking run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 09:13:12,422] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:13:12,427] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.463 seconds
[2019-09-10 09:13:50,027] {scheduler_job.py:146} INFO - Started process (PID=11569) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:50,028] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:13:50,028] {logging_mixin.py:95} INFO - [2019-09-10 09:13:50,028] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:50,259] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:13:50,259] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:13:50,278] {logging_mixin.py:95} INFO - [2019-09-10 09:13:50,277] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:13:55,052] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:13:55,100] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:13:55,110] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:13:55,115] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.088 seconds
[2019-09-10 09:14:32,084] {scheduler_job.py:146} INFO - Started process (PID=11607) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:14:32,085] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:14:32,085] {logging_mixin.py:95} INFO - [2019-09-10 09:14:32,085] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:14:32,318] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:14:32,319] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:14:32,339] {logging_mixin.py:95} INFO - [2019-09-10 09:14:32,338] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:14:36,853] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:14:36,902] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:14:36,910] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:14:36,915] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.831 seconds
[2019-09-10 09:15:14,132] {scheduler_job.py:146} INFO - Started process (PID=11655) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:15:14,134] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:15:14,134] {logging_mixin.py:95} INFO - [2019-09-10 09:15:14,134] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:15:14,384] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:15:14,384] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:15:14,403] {logging_mixin.py:95} INFO - [2019-09-10 09:15:14,403] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:15:18,961] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:15:19,018] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:15:19,033] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:15:19,040] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.908 seconds
[2019-09-10 09:15:56,196] {scheduler_job.py:146} INFO - Started process (PID=11701) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:15:56,199] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:15:56,199] {logging_mixin.py:95} INFO - [2019-09-10 09:15:56,199] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:15:56,470] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:15:56,471] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:15:56,490] {logging_mixin.py:95} INFO - [2019-09-10 09:15:56,490] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:16:00,422] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:16:00,473] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:16:00,485] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:16:00,491] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.295 seconds
[2019-09-10 09:16:38,247] {scheduler_job.py:146} INFO - Started process (PID=11747) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:16:38,252] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:16:38,252] {logging_mixin.py:95} INFO - [2019-09-10 09:16:38,252] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:16:38,506] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:16:38,506] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:16:38,526] {logging_mixin.py:95} INFO - [2019-09-10 09:16:38,526] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:16:42,717] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:16:42,753] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:16:42,759] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:16:42,764] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.518 seconds
[2019-09-10 09:17:20,291] {scheduler_job.py:146} INFO - Started process (PID=11796) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:17:20,292] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:17:20,293] {logging_mixin.py:95} INFO - [2019-09-10 09:17:20,293] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:17:20,560] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:17:20,561] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:17:20,581] {logging_mixin.py:95} INFO - [2019-09-10 09:17:20,581] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:17:25,211] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:17:25,242] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:17:25,248] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:17:25,253] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.962 seconds
[2019-09-10 09:18:02,351] {scheduler_job.py:146} INFO - Started process (PID=11832) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:02,352] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:18:02,353] {logging_mixin.py:95} INFO - [2019-09-10 09:18:02,353] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:02,590] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:18:02,590] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:18:02,609] {logging_mixin.py:95} INFO - [2019-09-10 09:18:02,608] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:18:07,917] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:07,953] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:18:07,959] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:18:07,964] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.613 seconds
[2019-09-10 09:18:44,411] {scheduler_job.py:146} INFO - Started process (PID=11870) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:44,416] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:18:44,417] {logging_mixin.py:95} INFO - [2019-09-10 09:18:44,417] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:44,669] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:18:44,669] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:18:44,687] {logging_mixin.py:95} INFO - [2019-09-10 09:18:44,687] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:18:49,186] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:18:49,241] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:18:49,251] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:18:49,257] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.846 seconds
[2019-09-10 09:19:26,456] {scheduler_job.py:146} INFO - Started process (PID=11913) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:19:26,457] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:19:26,457] {logging_mixin.py:95} INFO - [2019-09-10 09:19:26,457] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:19:26,691] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:19:26,691] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:19:26,709] {logging_mixin.py:95} INFO - [2019-09-10 09:19:26,709] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:19:28,852] {logging_mixin.py:95} INFO - [2019-09-10 09:19:28,850] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:19:28,853] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:19:28,887] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.431 seconds
[2019-09-10 09:20:08,511] {scheduler_job.py:146} INFO - Started process (PID=12009) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:08,516] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:20:08,517] {logging_mixin.py:95} INFO - [2019-09-10 09:20:08,517] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:08,780] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:20:08,781] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:20:08,812] {logging_mixin.py:95} INFO - [2019-09-10 09:20:08,812] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:20:10,932] {logging_mixin.py:95} INFO - [2019-09-10 09:20:10,931] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:20:10,933] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:10,969] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.458 seconds
[2019-09-10 09:20:50,561] {scheduler_job.py:146} INFO - Started process (PID=12058) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:50,566] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:20:50,566] {logging_mixin.py:95} INFO - [2019-09-10 09:20:50,566] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:50,834] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:20:50,834] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:20:50,853] {logging_mixin.py:95} INFO - [2019-09-10 09:20:50,853] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:20:53,624] {logging_mixin.py:95} INFO - [2019-09-10 09:20:53,624] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:20:53,625] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:20:53,650] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 3.090 seconds
[2019-09-10 09:21:32,610] {scheduler_job.py:146} INFO - Started process (PID=12111) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:21:32,615] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:21:32,616] {logging_mixin.py:95} INFO - [2019-09-10 09:21:32,616] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:21:32,941] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:21:32,941] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:21:32,962] {logging_mixin.py:95} INFO - [2019-09-10 09:21:32,961] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:21:36,744] {logging_mixin.py:95} INFO - [2019-09-10 09:21:36,743] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:21:36,744] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:21:36,767] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.157 seconds
[2019-09-10 09:22:14,652] {scheduler_job.py:146} INFO - Started process (PID=12172) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:14,659] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:22:14,660] {logging_mixin.py:95} INFO - [2019-09-10 09:22:14,660] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:14,995] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:22:14,995] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:22:15,018] {logging_mixin.py:95} INFO - [2019-09-10 09:22:15,017] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:22:17,312] {logging_mixin.py:95} INFO - [2019-09-10 09:22:17,311] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:22:17,313] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:17,350] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.698 seconds
[2019-09-10 09:22:56,688] {scheduler_job.py:146} INFO - Started process (PID=12309) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:56,691] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:22:56,691] {logging_mixin.py:95} INFO - [2019-09-10 09:22:56,691] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:56,937] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:22:56,937] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:22:56,955] {logging_mixin.py:95} INFO - [2019-09-10 09:22:56,955] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:22:59,142] {logging_mixin.py:95} INFO - [2019-09-10 09:22:59,141] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:22:59,142] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:22:59,165] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.476 seconds
[2019-09-10 09:23:38,739] {scheduler_job.py:146} INFO - Started process (PID=12373) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:23:38,741] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:23:38,741] {logging_mixin.py:95} INFO - [2019-09-10 09:23:38,741] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:23:39,017] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:23:39,017] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:23:39,041] {logging_mixin.py:95} INFO - [2019-09-10 09:23:39,040] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:23:41,510] {logging_mixin.py:95} INFO - [2019-09-10 09:23:41,509] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:23:41,511] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:23:41,548] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.809 seconds
[2019-09-10 09:24:20,794] {scheduler_job.py:146} INFO - Started process (PID=12442) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:24:20,797] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:24:20,797] {logging_mixin.py:95} INFO - [2019-09-10 09:24:20,797] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:24:21,047] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:24:21,047] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:24:21,066] {logging_mixin.py:95} INFO - [2019-09-10 09:24:21,066] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:24:23,605] {logging_mixin.py:95} INFO - [2019-09-10 09:24:23,604] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:24:23,606] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:24:23,640] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.846 seconds
[2019-09-10 09:25:02,840] {scheduler_job.py:146} INFO - Started process (PID=12497) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:02,846] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:25:02,846] {logging_mixin.py:95} INFO - [2019-09-10 09:25:02,846] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:03,096] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:25:03,097] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:25:03,115] {logging_mixin.py:95} INFO - [2019-09-10 09:25:03,115] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:25:05,484] {logging_mixin.py:95} INFO - [2019-09-10 09:25:05,484] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:25:05,485] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:05,510] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.669 seconds
[2019-09-10 09:25:44,898] {scheduler_job.py:146} INFO - Started process (PID=12551) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:44,904] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:25:44,905] {logging_mixin.py:95} INFO - [2019-09-10 09:25:44,905] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:45,248] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:25:45,249] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:25:45,281] {logging_mixin.py:95} INFO - [2019-09-10 09:25:45,280] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:25:47,374] {logging_mixin.py:95} INFO - [2019-09-10 09:25:47,372] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 12, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 71, in <module>
    python_callable= avg_fare_by_pclass,
NameError: name 'avg_fare_by_pclass' is not defined
[2019-09-10 09:25:47,375] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:25:47,406] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 2.509 seconds
[2019-09-10 09:26:26,944] {scheduler_job.py:146} INFO - Started process (PID=12610) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:26:26,951] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:26:26,952] {logging_mixin.py:95} INFO - [2019-09-10 09:26:26,951] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:26:27,213] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:26:27,214] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:26:27,234] {logging_mixin.py:95} INFO - [2019-09-10 09:26:27,233] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:26:31,219] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:26:31,256] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:26:31,264] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:26:31,288] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.344 seconds
[2019-09-10 09:27:08,987] {scheduler_job.py:146} INFO - Started process (PID=12658) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:08,988] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:27:08,988] {logging_mixin.py:95} INFO - [2019-09-10 09:27:08,988] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:09,226] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:27:09,226] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:27:09,248] {logging_mixin.py:95} INFO - [2019-09-10 09:27:09,247] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:27:15,872] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:15,916] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:27:15,924] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:27:15,931] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.944 seconds
[2019-09-10 09:27:51,048] {scheduler_job.py:146} INFO - Started process (PID=12698) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:51,053] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:27:51,054] {logging_mixin.py:95} INFO - [2019-09-10 09:27:51,054] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:51,324] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:27:51,324] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:27:51,345] {logging_mixin.py:95} INFO - [2019-09-10 09:27:51,344] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:27:56,872] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:27:56,931] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:27:56,941] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:27:56,947] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.899 seconds
[2019-09-10 09:28:33,101] {scheduler_job.py:146} INFO - Started process (PID=12737) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:28:33,106] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:28:33,107] {logging_mixin.py:95} INFO - [2019-09-10 09:28:33,107] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:28:33,366] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:28:33,367] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:28:33,387] {logging_mixin.py:95} INFO - [2019-09-10 09:28:33,386] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:28:38,327] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:28:38,395] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:28:38,412] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:28:38,470] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:28:38,473] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:28:38,476] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:28:38,478] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:28:38,509] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.408 seconds
[2019-09-10 09:30:02,640] {scheduler_job.py:146} INFO - Started process (PID=12873) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:30:02,641] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:30:02,642] {logging_mixin.py:95} INFO - [2019-09-10 09:30:02,642] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:30:02,891] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:30:02,892] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:30:02,911] {logging_mixin.py:95} INFO - [2019-09-10 09:30:02,910] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:30:07,675] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:30:07,714] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:30:07,722] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:30:07,741] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:30:07,743] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:30:07,771] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.131 seconds
[2019-09-10 09:31:00,708] {scheduler_job.py:146} INFO - Started process (PID=13036) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:31:00,709] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:31:00,709] {logging_mixin.py:95} INFO - [2019-09-10 09:31:00,709] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:31:00,959] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:31:00,960] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:31:00,980] {logging_mixin.py:95} INFO - [2019-09-10 09:31:00,979] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:31:06,106] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:31:06,136] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:31:06,141] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:31:06,160] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:31:06,162] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:31:06,184] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.476 seconds
[2019-09-10 09:31:57,782] {scheduler_job.py:146} INFO - Started process (PID=13105) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:31:57,784] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:31:57,784] {logging_mixin.py:95} INFO - [2019-09-10 09:31:57,784] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:31:58,017] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:31:58,018] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:31:58,036] {logging_mixin.py:95} INFO - [2019-09-10 09:31:58,036] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:32:02,538] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:32:02,588] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:32:02,600] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:32:02,623] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:32:02,625] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:32:02,647] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.864 seconds
[2019-09-10 09:32:57,078] {scheduler_job.py:146} INFO - Started process (PID=13181) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:32:57,079] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:32:57,079] {logging_mixin.py:95} INFO - [2019-09-10 09:32:57,079] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:32:57,311] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:32:57,312] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:32:57,330] {logging_mixin.py:95} INFO - [2019-09-10 09:32:57,330] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:33:01,663] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:33:01,718] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:33:01,727] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:33:01,819] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:33:01,823] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.745 seconds
[2019-09-10 09:33:39,140] {scheduler_job.py:146} INFO - Started process (PID=13230) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:33:39,145] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:33:39,145] {logging_mixin.py:95} INFO - [2019-09-10 09:33:39,145] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:33:39,426] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:33:39,426] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:33:39,445] {logging_mixin.py:95} INFO - [2019-09-10 09:33:39,444] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:33:49,063] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:33:49,098] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:33:49,105] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:33:49,111] {logging_mixin.py:95} INFO - [2019-09-10 09:33:49,111] {dagrun.py:308} INFO - Marking run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 09:33:49,129] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:33:49,134] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 9.995 seconds
[2019-09-10 09:34:21,177] {scheduler_job.py:146} INFO - Started process (PID=13294) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:34:21,179] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:34:21,179] {logging_mixin.py:95} INFO - [2019-09-10 09:34:21,179] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:34:21,521] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:34:21,522] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:34:21,552] {logging_mixin.py:95} INFO - [2019-09-10 09:34:21,551] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:34:25,746] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:34:25,794] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:34:25,801] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:34:25,806] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.629 seconds
[2019-09-10 09:35:03,236] {scheduler_job.py:146} INFO - Started process (PID=13341) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:35:03,241] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:35:03,242] {logging_mixin.py:95} INFO - [2019-09-10 09:35:03,242] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:35:03,529] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:35:03,530] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:35:03,548] {logging_mixin.py:95} INFO - [2019-09-10 09:35:03,548] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:35:07,831] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:35:07,865] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:35:07,871] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:35:07,896] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:35:07,899] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:35:07,940] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.704 seconds
[2019-09-10 09:36:00,103] {scheduler_job.py:146} INFO - Started process (PID=13444) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:36:00,105] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:36:00,105] {logging_mixin.py:95} INFO - [2019-09-10 09:36:00,105] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:36:00,335] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:36:00,336] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:36:00,355] {logging_mixin.py:95} INFO - [2019-09-10 09:36:00,354] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:36:04,912] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:36:04,953] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:36:04,962] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:36:04,984] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:36:04,986] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:36:05,008] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.905 seconds
[2019-09-10 09:36:57,023] {scheduler_job.py:146} INFO - Started process (PID=13815) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:36:57,024] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:36:57,024] {logging_mixin.py:95} INFO - [2019-09-10 09:36:57,024] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:36:57,283] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:36:57,283] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:36:57,304] {logging_mixin.py:95} INFO - [2019-09-10 09:36:57,303] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:37:01,502] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:37:01,559] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:37:01,570] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:37:01,593] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:37:01,595] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:37:01,616] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.594 seconds
[2019-09-10 09:37:54,113] {scheduler_job.py:146} INFO - Started process (PID=13988) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:37:54,119] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:37:54,119] {logging_mixin.py:95} INFO - [2019-09-10 09:37:54,119] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:37:54,576] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:37:54,577] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:37:54,604] {logging_mixin.py:95} INFO - [2019-09-10 09:37:54,604] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:37:58,813] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:37:58,881] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:37:58,896] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:37:58,917] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:37:58,919] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:37:58,921] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:37:58,923] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:37:58,945] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.833 seconds
[2019-09-10 09:39:25,616] {scheduler_job.py:146} INFO - Started process (PID=14196) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:39:25,617] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:39:25,618] {logging_mixin.py:95} INFO - [2019-09-10 09:39:25,618] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:39:25,859] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:39:25,859] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:39:25,879] {logging_mixin.py:95} INFO - [2019-09-10 09:39:25,878] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:39:29,631] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:39:29,666] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:39:29,673] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:39:29,679] {logging_mixin.py:95} INFO - [2019-09-10 09:39:29,679] {dagrun.py:308} INFO - Marking run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 09:39:29,697] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:39:29,703] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.086 seconds
[2019-09-10 09:40:07,669] {scheduler_job.py:146} INFO - Started process (PID=14252) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:07,670] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:40:07,671] {logging_mixin.py:95} INFO - [2019-09-10 09:40:07,671] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:07,910] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:40:07,911] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:40:07,930] {logging_mixin.py:95} INFO - [2019-09-10 09:40:07,930] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:40:11,626] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:11,662] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:40:11,671] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:40:11,678] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.009 seconds
[2019-09-10 09:40:49,714] {scheduler_job.py:146} INFO - Started process (PID=14322) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:49,715] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:40:49,716] {logging_mixin.py:95} INFO - [2019-09-10 09:40:49,716] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:49,968] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:40:49,968] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:40:49,987] {logging_mixin.py:95} INFO - [2019-09-10 09:40:49,987] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:40:53,453] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:40:53,495] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:40:53,503] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:40:53,509] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 3.795 seconds
[2019-09-10 09:41:31,780] {scheduler_job.py:146} INFO - Started process (PID=14367) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:41:31,786] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:41:31,788] {logging_mixin.py:95} INFO - [2019-09-10 09:41:31,787] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:41:32,083] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:41:32,083] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:41:32,110] {logging_mixin.py:95} INFO - [2019-09-10 09:41:32,109] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:41:36,555] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:41:36,598] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:41:36,606] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:41:36,611] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.831 seconds
[2019-09-10 09:42:13,807] {scheduler_job.py:146} INFO - Started process (PID=14441) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:42:13,809] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:42:13,809] {logging_mixin.py:95} INFO - [2019-09-10 09:42:13,809] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:42:14,048] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:42:14,048] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:42:14,068] {logging_mixin.py:95} INFO - [2019-09-10 09:42:14,068] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:42:18,138] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:42:18,205] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:42:18,219] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:42:18,226] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.418 seconds
[2019-09-10 09:42:55,863] {scheduler_job.py:146} INFO - Started process (PID=14475) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:42:55,868] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:42:55,868] {logging_mixin.py:95} INFO - [2019-09-10 09:42:55,868] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:42:56,119] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:42:56,120] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:42:56,138] {logging_mixin.py:95} INFO - [2019-09-10 09:42:56,138] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:43:00,144] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:43:00,203] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:43:00,212] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:43:00,218] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.355 seconds
[2019-09-10 09:43:37,902] {scheduler_job.py:146} INFO - Started process (PID=14510) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:43:37,903] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:43:37,903] {logging_mixin.py:95} INFO - [2019-09-10 09:43:37,903] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:43:38,140] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:43:38,140] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:43:38,159] {logging_mixin.py:95} INFO - [2019-09-10 09:43:38,159] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:43:42,145] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:43:42,206] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:43:42,218] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:43:42,224] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.322 seconds
[2019-09-10 09:44:19,953] {scheduler_job.py:146} INFO - Started process (PID=14552) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:44:19,955] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:44:19,955] {logging_mixin.py:95} INFO - [2019-09-10 09:44:19,955] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:44:20,201] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:44:20,202] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:44:20,221] {logging_mixin.py:95} INFO - [2019-09-10 09:44:20,220] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:44:24,410] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:44:24,463] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:44:24,473] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:44:24,479] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.525 seconds
[2019-09-10 09:45:02,020] {scheduler_job.py:146} INFO - Started process (PID=14588) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:02,025] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:45:02,025] {logging_mixin.py:95} INFO - [2019-09-10 09:45:02,025] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:02,280] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:45:02,281] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:45:02,300] {logging_mixin.py:95} INFO - [2019-09-10 09:45:02,300] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:45:06,396] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:06,448] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:45:06,460] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:45:06,467] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.447 seconds
[2019-09-10 09:45:44,065] {scheduler_job.py:146} INFO - Started process (PID=14629) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:44,066] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:45:44,067] {logging_mixin.py:95} INFO - [2019-09-10 09:45:44,066] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:44,301] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:45:44,301] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:45:44,320] {logging_mixin.py:95} INFO - [2019-09-10 09:45:44,320] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:45:50,226] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:45:50,275] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:45:50,284] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:45:50,290] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.224 seconds
[2019-09-10 09:46:26,130] {scheduler_job.py:146} INFO - Started process (PID=14683) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:46:26,136] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:46:26,137] {logging_mixin.py:95} INFO - [2019-09-10 09:46:26,137] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:46:26,441] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:46:26,441] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:46:26,463] {logging_mixin.py:95} INFO - [2019-09-10 09:46:26,462] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:46:30,584] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:46:30,634] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:46:30,642] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:46:30,648] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.518 seconds
[2019-09-10 09:47:08,174] {scheduler_job.py:146} INFO - Started process (PID=14751) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:08,181] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:47:08,182] {logging_mixin.py:95} INFO - [2019-09-10 09:47:08,182] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:09,207] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:47:09,210] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:47:09,296] {logging_mixin.py:95} INFO - [2019-09-10 09:47:09,294] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:47:14,444] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:14,507] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:47:14,528] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:47:14,545] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.370 seconds
[2019-09-10 09:47:50,220] {scheduler_job.py:146} INFO - Started process (PID=14802) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:50,228] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:47:50,229] {logging_mixin.py:95} INFO - [2019-09-10 09:47:50,229] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:51,392] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:47:51,395] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:47:51,493] {logging_mixin.py:95} INFO - [2019-09-10 09:47:51,491] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:47:55,890] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:47:55,963] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:47:55,985] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:47:56,003] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.783 seconds
[2019-09-10 09:48:32,262] {scheduler_job.py:146} INFO - Started process (PID=14853) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:48:32,269] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:48:32,270] {logging_mixin.py:95} INFO - [2019-09-10 09:48:32,270] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:48:33,287] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:48:33,289] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:48:33,648] {logging_mixin.py:95} INFO - [2019-09-10 09:48:33,646] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:48:39,177] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:48:39,246] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:48:39,272] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:48:39,289] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 7.026 seconds
[2019-09-10 09:49:14,305] {scheduler_job.py:146} INFO - Started process (PID=14905) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:49:14,312] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:49:14,313] {logging_mixin.py:95} INFO - [2019-09-10 09:49:14,313] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:49:15,318] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:49:15,320] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:49:15,674] {logging_mixin.py:95} INFO - [2019-09-10 09:49:15,672] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:49:20,269] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:49:20,353] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:49:20,372] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:49:20,443] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:49:20,451] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:49:20,492] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.186 seconds
[2019-09-10 09:50:14,614] {scheduler_job.py:146} INFO - Started process (PID=14992) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:50:14,621] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:50:14,621] {logging_mixin.py:95} INFO - [2019-09-10 09:50:14,621] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:50:15,621] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:50:15,623] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:50:15,982] {logging_mixin.py:95} INFO - [2019-09-10 09:50:15,980] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:50:20,686] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:50:20,750] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:50:20,769] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:50:20,862] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:50:20,869] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:50:20,910] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.296 seconds
[2019-09-10 09:51:20,485] {scheduler_job.py:146} INFO - Started process (PID=15099) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:51:20,487] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:51:20,487] {logging_mixin.py:95} INFO - [2019-09-10 09:51:20,487] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:51:20,732] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:51:20,732] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:51:20,819] {logging_mixin.py:95} INFO - [2019-09-10 09:51:20,818] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:51:25,251] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:51:25,310] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:51:25,320] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:51:25,340] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:51:25,342] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:51:25,364] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.879 seconds
[2019-09-10 09:52:21,945] {scheduler_job.py:146} INFO - Started process (PID=15164) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:52:21,946] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:52:21,946] {logging_mixin.py:95} INFO - [2019-09-10 09:52:21,946] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:52:22,179] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:52:22,179] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:52:22,259] {logging_mixin.py:95} INFO - [2019-09-10 09:52:22,259] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:52:26,332] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:52:26,367] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:52:26,374] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:52:26,394] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:52:26,398] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:52:26,400] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:52:26,402] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:52:26,423] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.479 seconds
[2019-09-10 09:53:49,453] {scheduler_job.py:146} INFO - Started process (PID=15318) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:53:49,457] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:53:49,457] {logging_mixin.py:95} INFO - [2019-09-10 09:53:49,457] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:53:49,729] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:53:49,730] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:53:49,816] {logging_mixin.py:95} INFO - [2019-09-10 09:53:49,816] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:53:53,704] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:53:53,747] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:53:53,755] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:53:53,762] {logging_mixin.py:95} INFO - [2019-09-10 09:53:53,762] {dagrun.py:308} INFO - Marking run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False> failed
[2019-09-10 09:53:53,781] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:53:53,784] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.332 seconds
[2019-09-10 09:54:31,500] {scheduler_job.py:146} INFO - Started process (PID=15374) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:54:31,506] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:54:31,506] {logging_mixin.py:95} INFO - [2019-09-10 09:54:31,506] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:54:31,761] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:54:31,762] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:54:31,849] {logging_mixin.py:95} INFO - [2019-09-10 09:54:31,848] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:54:37,018] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:54:37,062] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:54:37,067] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:54:37,071] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.572 seconds
[2019-09-10 09:55:13,533] {scheduler_job.py:146} INFO - Started process (PID=15451) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:55:13,535] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:55:13,536] {logging_mixin.py:95} INFO - [2019-09-10 09:55:13,536] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:55:13,848] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:55:13,849] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:55:13,942] {logging_mixin.py:95} INFO - [2019-09-10 09:55:13,942] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:55:18,387] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:55:18,454] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:55:18,471] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:55:18,484] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.950 seconds
[2019-09-10 09:55:55,583] {scheduler_job.py:146} INFO - Started process (PID=15488) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:55:55,585] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:55:55,585] {logging_mixin.py:95} INFO - [2019-09-10 09:55:55,585] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:55:55,824] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:55:55,824] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:55:55,905] {logging_mixin.py:95} INFO - [2019-09-10 09:55:55,904] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:56:02,209] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:56:02,240] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:56:02,247] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:56:02,253] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.669 seconds
[2019-09-10 09:56:37,636] {scheduler_job.py:146} INFO - Started process (PID=15540) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:56:37,638] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:56:37,638] {logging_mixin.py:95} INFO - [2019-09-10 09:56:37,638] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:56:37,894] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:56:37,894] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:56:37,982] {logging_mixin.py:95} INFO - [2019-09-10 09:56:37,981] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:56:46,838] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:56:46,877] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:56:46,884] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:56:46,890] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 9.254 seconds
[2019-09-10 09:57:19,691] {scheduler_job.py:146} INFO - Started process (PID=15568) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:57:19,693] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:57:19,693] {logging_mixin.py:95} INFO - [2019-09-10 09:57:19,693] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:57:19,933] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:57:19,933] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:57:20,013] {logging_mixin.py:95} INFO - [2019-09-10 09:57:20,013] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:57:24,043] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:57:24,102] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:57:24,115] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:57:24,122] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.430 seconds
[2019-09-10 09:58:01,742] {scheduler_job.py:146} INFO - Started process (PID=15609) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:01,744] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:58:01,744] {logging_mixin.py:95} INFO - [2019-09-10 09:58:01,744] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:01,984] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:58:01,984] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:58:02,064] {logging_mixin.py:95} INFO - [2019-09-10 09:58:02,064] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:58:06,642] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:06,676] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:58:06,683] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:58:06,687] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.945 seconds
[2019-09-10 09:58:43,792] {scheduler_job.py:146} INFO - Started process (PID=15650) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:43,793] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:58:43,793] {logging_mixin.py:95} INFO - [2019-09-10 09:58:43,793] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:44,032] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:58:44,032] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:58:44,111] {logging_mixin.py:95} INFO - [2019-09-10 09:58:44,111] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:58:50,079] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:58:50,110] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:58:50,116] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:58:50,137] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:58:50,139] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.dummy_start 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:58:50,162] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.370 seconds
[2019-09-10 09:59:35,083] {scheduler_job.py:146} INFO - Started process (PID=15709) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 09:59:35,084] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 09:59:35,084] {logging_mixin.py:95} INFO - [2019-09-10 09:59:35,084] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:59:35,324] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:59:35,324] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 09:59:35,404] {logging_mixin.py:95} INFO - [2019-09-10 09:59:35,404] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 09:59:39,973] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 09:59:40,010] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 09:59:40,018] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 09:59:40,043] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 09:59:40,045] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.upload_file_to_s3 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 09:59:40,073] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.990 seconds
[2019-09-10 10:00:31,676] {scheduler_job.py:146} INFO - Started process (PID=15787) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:00:31,677] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:00:31,678] {logging_mixin.py:95} INFO - [2019-09-10 10:00:31,678] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:00:31,916] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:00:31,917] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:00:31,997] {logging_mixin.py:95} INFO - [2019-09-10 10:00:31,997] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:00:38,327] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:00:38,358] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 10:00:38,364] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:00:38,385] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:00:38,387] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.read_csv 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:00:38,410] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.734 seconds
[2019-09-10 10:01:28,481] {scheduler_job.py:146} INFO - Started process (PID=15866) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:01:28,482] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:01:28,482] {logging_mixin.py:95} INFO - [2019-09-10 10:01:28,482] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:01:28,717] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:01:28,718] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:01:28,801] {logging_mixin.py:95} INFO - [2019-09-10 10:01:28,800] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:01:39,025] {scheduler_job.py:1532} INFO - DAG(s) dict_keys(['ahhaha_titanic_analysis']) retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:01:39,086] {scheduler_job.py:1255} INFO - Processing ahhaha_titanic_analysis
[2019-09-10 10:01:39,098] {scheduler_job.py:729} INFO - Examining DAG run <DagRun ahhaha_titanic_analysis @ 2019-01-01 00:00:00+00:00: scheduled__2019-01-01T00:00:00+00:00, externally triggered: False>
[2019-09-10 10:01:39,117] {scheduler_job.py:429} INFO - Skipping SLA check for <DAG: ahhaha_titanic_analysis> because no tasks in DAG have SLAs
[2019-09-10 10:01:39,120] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.most_survived_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:01:39,122] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.avg_fare_by_pclass 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:01:39,124] {scheduler_job.py:1596} INFO - Creating / updating <TaskInstance: ahhaha_titanic_analysis.num_of_survivors 2019-01-01 00:00:00+00:00 [scheduled]> in ORM
[2019-09-10 10:01:39,156] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 10.675 seconds
[2019-09-10 10:02:59,158] {scheduler_job.py:146} INFO - Started process (PID=16023) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:02:59,163] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:02:59,164] {logging_mixin.py:95} INFO - [2019-09-10 10:02:59,164] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:02:59,422] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:02:59,423] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:02:59,508] {logging_mixin.py:95} INFO - [2019-09-10 10:02:59,508] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:03:04,071] {logging_mixin.py:95} INFO - [2019-09-10 10:03:04,064] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:03:04,071] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:03:04,102] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.945 seconds
[2019-09-10 10:03:41,194] {scheduler_job.py:146} INFO - Started process (PID=16064) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:03:41,196] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:03:41,196] {logging_mixin.py:95} INFO - [2019-09-10 10:03:41,196] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:03:41,588] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:03:41,589] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:03:41,690] {logging_mixin.py:95} INFO - [2019-09-10 10:03:41,690] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:03:47,209] {logging_mixin.py:95} INFO - [2019-09-10 10:03:47,202] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:03:47,210] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:03:47,276] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.082 seconds
[2019-09-10 10:04:23,243] {scheduler_job.py:146} INFO - Started process (PID=16102) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:04:23,245] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:04:23,245] {logging_mixin.py:95} INFO - [2019-09-10 10:04:23,245] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:04:23,621] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:04:23,621] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:04:23,714] {logging_mixin.py:95} INFO - [2019-09-10 10:04:23,713] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:04:28,268] {logging_mixin.py:95} INFO - [2019-09-10 10:04:28,262] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:04:28,269] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:04:28,303] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.060 seconds
[2019-09-10 10:05:05,297] {scheduler_job.py:146} INFO - Started process (PID=16221) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:05,300] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:05:05,300] {logging_mixin.py:95} INFO - [2019-09-10 10:05:05,300] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:05,558] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:05:05,558] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:05:05,643] {logging_mixin.py:95} INFO - [2019-09-10 10:05:05,643] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:05:11,416] {logging_mixin.py:95} INFO - [2019-09-10 10:05:11,406] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:05:11,417] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:11,453] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.156 seconds
[2019-09-10 10:05:47,341] {scheduler_job.py:146} INFO - Started process (PID=16274) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:47,342] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:05:47,343] {logging_mixin.py:95} INFO - [2019-09-10 10:05:47,343] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:47,672] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:05:47,672] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:05:47,763] {logging_mixin.py:95} INFO - [2019-09-10 10:05:47,763] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:05:52,471] {logging_mixin.py:95} INFO - [2019-09-10 10:05:52,468] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:05:52,471] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:05:52,497] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.157 seconds
[2019-09-10 10:06:29,393] {scheduler_job.py:146} INFO - Started process (PID=16328) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:06:29,396] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:06:29,396] {logging_mixin.py:95} INFO - [2019-09-10 10:06:29,396] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:06:29,719] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:06:29,719] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:06:29,816] {logging_mixin.py:95} INFO - [2019-09-10 10:06:29,816] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:06:35,690] {logging_mixin.py:95} INFO - [2019-09-10 10:06:35,687] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:06:35,690] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:06:35,717] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 6.324 seconds
[2019-09-10 10:07:11,449] {scheduler_job.py:146} INFO - Started process (PID=16384) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:11,453] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:07:11,454] {logging_mixin.py:95} INFO - [2019-09-10 10:07:11,454] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:11,731] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:07:11,731] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:07:11,815] {logging_mixin.py:95} INFO - [2019-09-10 10:07:11,815] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:07:16,406] {logging_mixin.py:95} INFO - [2019-09-10 10:07:16,404] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:07:16,406] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:16,432] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.984 seconds
[2019-09-10 10:07:53,487] {scheduler_job.py:146} INFO - Started process (PID=16432) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:53,488] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:07:53,488] {logging_mixin.py:95} INFO - [2019-09-10 10:07:53,488] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:53,722] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:07:53,722] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:07:53,803] {logging_mixin.py:95} INFO - [2019-09-10 10:07:53,803] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:07:58,628] {logging_mixin.py:95} INFO - [2019-09-10 10:07:58,625] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:07:58,629] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:07:58,658] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.171 seconds
[2019-09-10 10:08:35,538] {scheduler_job.py:146} INFO - Started process (PID=16528) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:08:35,540] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:08:35,541] {logging_mixin.py:95} INFO - [2019-09-10 10:08:35,541] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:08:35,837] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:08:35,838] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:08:35,931] {logging_mixin.py:95} INFO - [2019-09-10 10:08:35,930] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:08:41,099] {logging_mixin.py:95} INFO - [2019-09-10 10:08:41,092] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:08:41,099] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:08:41,134] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.596 seconds
[2019-09-10 10:09:17,593] {scheduler_job.py:146} INFO - Started process (PID=16614) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:09:17,594] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:09:17,595] {logging_mixin.py:95} INFO - [2019-09-10 10:09:17,595] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:09:17,833] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:09:17,834] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:09:17,931] {logging_mixin.py:95} INFO - [2019-09-10 10:09:17,930] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:09:22,168] {logging_mixin.py:95} INFO - [2019-09-10 10:09:22,162] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:09:22,169] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:09:22,201] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.609 seconds
[2019-09-10 10:09:59,643] {scheduler_job.py:146} INFO - Started process (PID=16668) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:09:59,644] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:09:59,644] {logging_mixin.py:95} INFO - [2019-09-10 10:09:59,644] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:10:00,025] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:10:00,025] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:10:00,174] {logging_mixin.py:95} INFO - [2019-09-10 10:10:00,173] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:10:04,868] {logging_mixin.py:95} INFO - [2019-09-10 10:10:04,861] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:10:04,868] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:10:04,903] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.260 seconds
[2019-09-10 10:10:41,695] {scheduler_job.py:146} INFO - Started process (PID=16756) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:10:41,697] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:10:41,697] {logging_mixin.py:95} INFO - [2019-09-10 10:10:41,697] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:10:41,940] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:10:41,940] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:10:42,019] {logging_mixin.py:95} INFO - [2019-09-10 10:10:42,019] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:10:46,566] {logging_mixin.py:95} INFO - [2019-09-10 10:10:46,560] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:10:46,567] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:10:46,602] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.907 seconds
[2019-09-10 10:11:53,738] {scheduler_job.py:146} INFO - Started process (PID=16929) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:11:53,739] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:11:53,739] {logging_mixin.py:95} INFO - [2019-09-10 10:11:53,739] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:11:53,985] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:11:53,986] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:11:54,107] {logging_mixin.py:95} INFO - [2019-09-10 10:11:54,106] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:11:58,686] {logging_mixin.py:95} INFO - [2019-09-10 10:11:58,685] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:11:58,686] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:11:58,713] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.975 seconds
[2019-09-10 10:12:35,784] {scheduler_job.py:146} INFO - Started process (PID=17027) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:12:35,787] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:12:35,787] {logging_mixin.py:95} INFO - [2019-09-10 10:12:35,787] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:12:36,022] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:12:36,022] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:12:36,103] {logging_mixin.py:95} INFO - [2019-09-10 10:12:36,102] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:12:41,317] {logging_mixin.py:95} INFO - [2019-09-10 10:12:41,310] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:12:41,318] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:12:41,352] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.568 seconds
[2019-09-10 10:13:17,830] {scheduler_job.py:146} INFO - Started process (PID=17404) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:13:17,833] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:13:17,834] {logging_mixin.py:95} INFO - [2019-09-10 10:13:17,833] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:13:18,188] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:13:18,189] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:13:18,296] {logging_mixin.py:95} INFO - [2019-09-10 10:13:18,295] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:13:22,385] {logging_mixin.py:95} INFO - [2019-09-10 10:13:22,381] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:13:22,385] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:13:22,413] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 4.583 seconds
[2019-09-10 10:13:59,868] {scheduler_job.py:146} INFO - Started process (PID=17487) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:13:59,872] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:13:59,872] {logging_mixin.py:95} INFO - [2019-09-10 10:13:59,872] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:14:00,124] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:14:00,124] {logging_mixin.py:95} WARNING - /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
  DeprecationWarning)
[2019-09-10 10:14:00,203] {logging_mixin.py:95} INFO - [2019-09-10 10:14:00,203] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-10 10:14:05,078] {logging_mixin.py:95} INFO - [2019-09-10 10:14:05,076] {dagbag.py:205} ERROR - Failed to import: /home/jennie/airflow/dags/operations.py
Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 30, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 509, in info
    raise FileNotFoundError(path)
FileNotFoundError: airflow-demo-09092019/titanic-train.csv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 332, in _lsdir
    for i in it:
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 255, in __iter__
    response = self._make_request(current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/paginate.py", line 332, in _make_request
    return self._method(**current_kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/botocore/client.py", line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/models/dagbag.py", line 202, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jennie/airflow/dags/operations.py", line 14, in <module>
    from operations import *
  File "/home/jennie/airflow/dags/operations.py", line 59, in <module>
    titanic_df = read_csv_from_s3(s3_filename, bucket_name)
  File "/home/jennie/airflow/dags/task3_read.py", line 7, in read_csv_from_s3
    titanic_df = pd.read_csv(s3_file_path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 685, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/parsers.py", line 440, in _read
    filepath_or_buffer, encoding, compression
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/common.py", line 209, in get_filepath_or_buffer
    filepath_or_buffer, encoding=encoding, compression=compression, mode=mode
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 49, in get_filepath_or_buffer
    file, _fs = get_file_and_filesystem(filepath_or_buffer, mode=mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/pandas/io/s3.py", line 39, in get_file_and_filesystem
    file = fs.open(_strip_schema(filepath_or_buffer), mode)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 689, in open
    autocommit=ac, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 314, in _open
    autocommit=autocommit)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 939, in __init__
    cache_type=cache_type)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 884, in __init__
    self.details = fs.info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 498, in info
    return super().info(path)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/fsspec/spec.py", line 495, in info
    out = self.ls(self._parent(path), detail=True, **kwargs)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 516, in ls
    files = self._ls(path, refresh=refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 441, in _ls
    return self._lsdir(path, refresh)
  File "/home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/s3fs/core.py", line 347, in _lsdir
    raise translate_boto_error(e)
PermissionError: Access Denied
[2019-09-10 10:14:05,078] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:14:05,105] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 5.236 seconds
[2019-09-10 10:14:41,914] {scheduler_job.py:146} INFO - Started process (PID=17554) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:14:41,916] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:14:41,917] {logging_mixin.py:95} INFO - [2019-09-10 10:14:41,917] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:14:41,917] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:14:41,917] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.003 seconds
[2019-09-10 10:15:23,970] {scheduler_job.py:146} INFO - Started process (PID=17606) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:15:23,971] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:15:23,972] {logging_mixin.py:95} INFO - [2019-09-10 10:15:23,972] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:15:23,972] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:15:23,972] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.002 seconds
[2019-09-10 10:16:06,012] {scheduler_job.py:146} INFO - Started process (PID=17644) to work on /home/jennie/airflow/dags/operations.py
[2019-09-10 10:16:06,014] {scheduler_job.py:1520} INFO - Processing file /home/jennie/airflow/dags/operations.py for tasks to queue
[2019-09-10 10:16:06,014] {logging_mixin.py:95} INFO - [2019-09-10 10:16:06,014] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:16:06,015] {scheduler_job.py:1534} WARNING - No viable dags retrieved from /home/jennie/airflow/dags/operations.py
[2019-09-10 10:16:06,015] {scheduler_job.py:152} INFO - Processing /home/jennie/airflow/dags/operations.py took 0.003 seconds
