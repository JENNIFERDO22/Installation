[2019-09-09 09:58:36,631] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: s3_dag_test.upload_file_to_s3 2019-01-01T00:00:00+00:00 [queued]>
[2019-09-09 09:58:36,638] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: s3_dag_test.upload_file_to_s3 2019-01-01T00:00:00+00:00 [queued]>
[2019-09-09 09:58:36,638] {taskinstance.py:838} INFO - 
--------------------------------------------------------------------------------
[2019-09-09 09:58:36,638] {taskinstance.py:839} INFO - Starting attempt 8 of 8
[2019-09-09 09:58:36,638] {taskinstance.py:840} INFO - 
--------------------------------------------------------------------------------
[2019-09-09 09:58:36,659] {taskinstance.py:859} INFO - Executing <Task(PythonOperator): upload_file_to_s3> on 2019-01-01T00:00:00+00:00
[2019-09-09 09:58:36,659] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 's3_dag_test', 'upload_file_to_s3', '2019-01-01T00:00:00+00:00', '--job_id', '23', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/upload_file_to_s3.py', '--cfg_path', '/tmp/tmp4w4i2g3j']
[2019-09-09 09:58:37,207] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 [2019-09-09 09:58:37,206] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-09-09 09:58:37,504] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 [2019-09-09 09:58:37,504] {dagbag.py:90} INFO - Filling up the DagBag from /home/jennie/airflow/dags/upload_file_to_s3.py
[2019-09-09 09:58:37,507] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'DummyOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2019-09-09 09:58:37,507] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3   DeprecationWarning)
[2019-09-09 09:58:37,508] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 /home/jennie/workspace/airflow_venv/lib/python3.7/site-packages/airflow/utils/helpers.py:423: DeprecationWarning: Importing 'PythonOperator' directly from 'airflow.operators' has been deprecated. Please import from 'airflow.operators.[operator_module]' instead. Support for direct imports will be dropped entirely in Airflow 2.0.
[2019-09-09 09:58:37,509] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3   DeprecationWarning)
[2019-09-09 09:58:37,705] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 [2019-09-09 09:58:37,705] {credentials.py:1182} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2019-09-09 09:58:37,729] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 None
[2019-09-09 09:58:37,738] {base_task_runner.py:115} INFO - Job 23: Subtask upload_file_to_s3 [2019-09-09 09:58:37,738] {cli.py:516} INFO - Running <TaskInstance: s3_dag_test.upload_file_to_s3 2019-01-01T00:00:00+00:00 [running]> on host Jennie-ubuntu-GX501VSK
[2019-09-09 09:58:37,743] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=s3_dag_test
AIRFLOW_CTX_TASK_ID=upload_file_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2019-09-09 09:58:37,743] {logging_mixin.py:95} INFO - Uploading to s3
[2019-09-09 09:58:39,922] {python_operator.py:114} INFO - Done. Returned value was: None
[2019-09-09 09:58:41,647] {logging_mixin.py:95} INFO - [[34m2019-09-09 09:58:41,646[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 0[0m
